{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Ensure your virtual environment\n",
    "\n",
    "Run `python script/install_venv_packages.py --require_jupyter`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Ensure your virtual environment\n",
    "\n",
    "Run `python script/preprocess_work_dir.py --dataset daco`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Setup your default model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "\n",
    "from argos import ArgosAgent, ArgosConfig\n",
    "\n",
    "# ==== You can uncomment the following lines to inspect the client calls (using agent._client_calls)\n",
    "# import argos.agent\n",
    "# argos.agent.MONKEY_PATCH_TO_SAVE_CALLS = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_config(entry_id):\n",
    "    work_dir = f\"../work/daco/{entry_id}\"\n",
    "    \n",
    "    with open(f\"{work_dir}/meta.json\", \"r\") as f:\n",
    "        meta = json.load(f)\n",
    "    \n",
    "    dataset_names = meta['dataset_names']     \n",
    "    question = meta['question']  \n",
    "    \n",
    "    config = ArgosConfig(\n",
    "        work_dir=work_dir,\n",
    "        dataset_names=dataset_names,\n",
    "        question=question,\n",
    "        venv_dir=\"../work/venv\",\n",
    "        default_model_name=\"gpt-4o-mini\",\n",
    "        default_api_key=\"<your-openai-api-key>\", # replace this line with your OpenAI API key\n",
    "        default_base_url=\"https://<openai-endpoint>/v1\" # replace this line with your OpenAI endpoint\n",
    "    )\n",
    "    \n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Argos on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_one_entry(entry_id):\n",
    "    config = get_model_config(entry_id)\n",
    "    agent = ArgosAgent(config)\n",
    "    await agent.run(print_to_console=False)  # If you want to inspect the intermediate results, set print_to_console=True\n",
    "    await agent.save_task_result()  # This will save `task_result.json` to the work directory\n",
    "    await agent.save_data_report()  # This will save `report.json` and `report.md` to the work directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry_id in tqdm(os.listdir(\"../work/daco\")):\n",
    "    try:\n",
    "        await process_one_entry(entry_id)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {entry_id}: {e}, please try again. \")\n",
    "        continue\n",
    "    \n",
    "# ==== You can also:\n",
    "# 1. use asyncio.gather() to run multiple entries concurrently, which can speed up the process\n",
    "# 2. modify the `process_one_entry` function to skip entries that have already been processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Collect the reports, then evaluate them\n",
    "\n",
    "Run `python script/collect_reports.py`\n",
    "\n",
    "Run `python script/eval/daco/eval_helpfulness.py --model_type vllm --vllm_base_url <your-vllm-endpoint> --model \"Llama-3-8B-Instruct\" --api_key \"EMPTY\" --pred \"work/output/daco_collected_reports.json\"`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
