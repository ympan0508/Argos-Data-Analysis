{"id": "kaggle__lukexun__luke-hair-loss-dataset__0", "question": "I have a database of Luke Hair Loss Dataset. As a personal care product retailer, I want to evaluate the relationship between hair washing habits and hair loss to recommend suitable products to customers.", "description": "\n\nLuke Hair Loss Dataset\n\nLuke_hair_loss_documentation\n396 rows x 12 columns\n1. date  | object | 1/01/2021 | 2/01/2021 | 3/01/2021 | 4/01/2021 | 5/01/2021\n2. hair_loss | object | Few | Few | Medium | Few | Few\n3. stay_up_late | int64 | 2 | 0 | 3 | 2 | 2\n4. pressure_level | object | Low | Low | Low | Low | Low\n5. coffee_consumed | int64 | 0 | 0 | 1 | 0 | 0\n6. brain_working_duration | int64 | 1 | 3 | 0 | 1 | 1\n7. stress_level | object | Low | Low | Low | Low | Low\n8. shampoo_brand | object | Pantene | Pantene | Pantene | Pantene | Pantene\n9. swimming | object | No | No | Yes | No | No\n10. hair_washing | object | Y | N | Y | N | Y\n11. hair_grease | float64 | 3.0 | 1.0 | 2.0 | 3.0 | 1.0\n12. libido | int64 | 1 | 1 | 2 | 3 | 2\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__lukexun__luke-hair-loss-dataset/Luke_hair_loss_documentation.csv"]}
{"id": "kaggle__utkarshx27__lovoo-dating-app-dataset__0", "question": "I have a database of Dating App Fame & Behavior. As a business development manager, I want to analyze user behavior to identify potential partnership opportunities with other companies or brands.", "description": "\n\nDating App Fame & Behavior\n\ninterests-of-users-by-age\n11 rows x 16 columns\n1. age | int64 | 18 | 19 | 20 | 21 | 22\n2. nbusers | int64 | 1 | 523 | 524 | 603 | 720\n3. percentwantchats | float64 | 0.0 | 65.8 | 67.6 | 64.0 | 59.9\n4. percentwantfriends | float64 | 0.0 | 62.5 | 64.9 | 63.0 | 60.6\n5. percentwantdates | float64 | 0.0 | 34.2 | 37.2 | 35.7 | 40.3\n6. meankissesreceived | int64 | 0 | 179 | 208 | 167 | 134\n7. meanvisitsreceived | float64 | 0.0 | 4279.5 | 4809.5 | 4093.0 | 3302.9\n8. meanfollowers | float64 | 0.0 | 2.6 | 1.8 | 2.1 | 1.7\n9. meanlanguagesknown | float64 | 1.0 | 1.15 | 1.12 | 1.12 | 1.07\n10. totalwantchants | int64 | 0 | 344 | 354 | 386 | 431\n11. totalwantfriends | int64 | 0 | 327 | 340 | 380 | 436\n12. totalwantdates | int64 | 0 | 179 | 195 | 215 | 290\n13. totalkissesreceive | int64 | 0 | 93985 | 109490 | 101063 | 96505\n14. totalvisitsreceived | int64 | 0 | 2238190 | 2520195 | 2468100 | 2378122\n15. totalfollowers | int64 | 0 | 1374 | 934 | 1239 | 1201\n16. totallanguagesspoken | int64 | 1 | 601 | 586 | 678 | 771\n\nlovoo_v3_users_api-results\n2260 rows x 39 columns\n1. gender | object | F | F | F | F | F\n2. genderLooking | object | M | M | none | M | M\n3. age | int64 | 25 | 22 | 20 | 21 | 24\n4. name | object | daeni | italiana 92 | Qqkwmdowlo | schaessie {3 | Baby dee\n5. counts_details | float64 | 1.0 | 0.85 | 0.12 | 0.15 | 0.81\n6. counts_pictures | int64 | 4 | 5 | 3 | 12 | 18\n7. counts_profileVisits | int64 | 8279 | 663 | 22187 | 35262 | 7339\n8. counts_kisses | int64 | 239 | 13 | 1015 | 1413 | 180\n9. counts_fans | int64 | 0 | 0 | 2 | 9 | 0\n10. counts_g | int64 | 3 | 0 | 3 | 12 | 2\n11. flirtInterests_chat | bool | True | True | True | True | True\n12. flirtInterests_friends | bool | True | True | True | False | False\n13. flirtInterests_date | bool | True | True | False | False | True\n14. country | object | CH | CH | CA | DE | DE\n15. city | object | Rothenburg | Sissach | Montr√©al | Rastatt | Titisee-Neustadt\n16. location | object | R√ºmlang | Sissach | Berne | Rastatt | Titisee-Neustadt\n17. distance | float64 | 175.0 | 138.0 | 77.3 | 286.0 | 194.0\n18. isFlirtstar | int64 | 0 | 0 | 0 | 0 | 0\n19. isHighlighted | int64 | 0 | 0 | 0 | 0 | 0\n20. isInfluencer | int64 | 0 | 0 | 0 | 0 | 0\n21. isMobile | int64 | 1 | 1 | 0 | 0 | 1\n22. isNew | int64 | 0 | 0 | 0 | 0 | 0\n23. isOnline | int64 | 0 | 0 | 0 | 1 | 1\n24. isVip | int64 | 0 | 0 | 0 | 0 | 0\n25. lang_count | int64 | 1 | 3 | 2 | 1 | 2\n26. lang_fr | bool | False | True | True | False | False\n27. lang_en | bool | False | False | True | False | True\n28. lang_de | bool | True | True | False | True | True\n29. lang_it | bool | False | True | False | False | False\n30. lang_es | bool | False | False | False | False | False\n31. lang_pt | bool | False | False | False | False | False\n32. verified | int64 | 0 | 0 | 0 | 0 | 0\n33. shareProfileEnabled | int64 | 1 | 1 | 1 | 1 | 1\n34. lastOnlineDate | object | 2015-04-25T20:43:26Z | 2015-04-26T09:19:35Z | 2015-04-07T11:21:01Z | 2015-04-06T14:25:20Z | 2015-04-08T14:37:51Z\n35. lastOnlineTime | float64 | 1429994606.0 | 1430039975.0 | 1428405661.0 | 1428330320.0 | 1428503871.0\n36. birthd | int64 | 0 | 0 | 0 | 0 | 0\n37. whazzup | object | Nur tote fische schwimmen mit dem strom | Primaveraaa<3 | Je pense donc je suis.  Instagram quedev | Instagram: JESSSIESCH | Wicked Wonderlandüíï‚ù§Ô∏è\n38. pictureId | object | 4e3842f79b70e7ea57000064 | 4e3d34bf5d2bce7b160006a3 | 4eef8b81ebf2c8f64000000c | 4ef3cc5aa9d0b3d07d000017 | 4ef9434cca61bece6a000002\n39. userId | object | 55303fc3160ba0eb728b4575 | 552e7b61c66da10d1e8b4c82 | 54c92738076ea1b5338b4735 | 54e1a6f6c76da135748b4a3a | 54f2b4ce0b6ea1177e8b4d18\n\nlovoo_v3_users_instances\n2643 rows x 36 columns\n1. gender | object | F | F | F | F | F\n2. age | int64 | 25 | 22 | 20 | 24 | 24\n3. name | object | daeni | italiana 92 | Qqkwmdowlo | Baby dee | Anna\n4. counts_pictures | int64 | 4 | 5 | 3 | 18 | 13\n5. counts_profileVisits | int64 | 8279 | 663 | 22187 | 7339 | 18672\n6. counts_kisses | int64 | 239 | 13 | 1015 | 180 | 492\n7. flirtInterests_chat | bool | True | True | True | True | False\n8. flirtInterests_friends | bool | True | True | True | False | True\n9. flirtInterests_date | bool | True | True | False | True | False\n10. connectedToFacebook | bool | False | False | False | False | False\n11. isVIP | bool | False | False | False | False | False\n12. isVerified | bool | False | False | False | False | False\n13. lastOnline | object | 2015-04-25 20:43:26 | 2015-04-26 09:19:35 | 2015-04-07 11:21:01 | 2015-04-08 14:37:51 | 2015-04-27 19:29:58\n14. lastOnlineTs | float64 | 1429994606.0 | 1430039975.0 | 1428405661.0 | 1428503871.0 | 1430162998.0\n15. lang_count | int64 | 1 | 3 | 2 | 2 | 5\n16. lang_fr | bool | False | True | True | False | False\n17. lang_en | bool | False | False | True | True | True\n18. lang_de | bool | True | True | False | True | True\n19. lang_it | bool | False | True | False | False | False\n20. lang_es | bool | False | False | False | False | False\n21. lang_pt | bool | False | False | False | False | False\n22. city | object | Rothenburg | Sissach | Montr√©al | Titisee-Neustadt | Stuttgart\n23. locationCity | object | R√ºmlang | Sissach | Berne | Titisee-Neustadt | Stuttgart\n24. countDetails | float64 | 1.0 | 0.8500000238418579 | 0.1199999973177909 | 0.8100000023841858 | 0.6499999761581421\n25. crypt | bool | False | False | False | False | False\n26. flirtstar | bool | False | False | False | False | False\n27. freshman | bool | False | False | False | False | False\n28. hasBirthday | bool | False | False | False | False | False\n29. highlighted | bool | False | False | False | False | False\n30. distance | float64 | 175.0 | 138.0 | 77.30000305175781 | 194.0 | 318.0\n31. locked | bool | False | False | False | False | False\n32. mobile | bool | True | True | False | True | True\n33. online | bool | False | False | False | True | True\n34. pictureId | object | 4e3842f79b70e7ea57000064 | 4e3d34bf5d2bce7b160006a3 | 4eef8b81ebf2c8f64000000c | 4ef9434cca61bece6a000002 | 4f10cbc1883fa97a5f000015\n35. userId | object | 55303fc3160ba0eb728b4575 | 552e7b61c66da10d1e8b4c82 | 54c92738076ea1b5338b4735 | 54f2b4ce0b6ea1177e8b4d18 | 54ecbb39170ba08b488b4aa5\n36. isSystemProfile | bool | False | False | False | False | False\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__utkarshx27__lovoo-dating-app-dataset/interests-of-users-by-age.csv", "csv/kaggle__utkarshx27__lovoo-dating-app-dataset/lovoo_v3_users_api-results.csv", "csv/kaggle__utkarshx27__lovoo-dating-app-dataset/lovoo_v3_users_instances.csv"]}
{"id": "kaggle__suvarnayandapalli__fruit-classification-data__0", "question": "I have a database of Fruit classification data. As a farmer, I want to determine the suitable fruit varieties to grow on my farm.", "description": "\n\nFruit classification data\n\nfruit\n49 rows x 6 columns\n1. id | int64 | 1 | 2 | 3 | 4 | 5\n2. fruit_name | object | Apple | Orange | Banana | Apple | Orange\n3. color | object | Red | Orange | Yellow | Green | Orange\n4. diameter | float64 | 7.6 | 7.2 | 6.8 | 7.5 | 7.0\n5. weight | float64 | 150.0 | 180.0 | 120.0 | 155.0 | 175.0\n6. texture | object | Crisp | Smooth | Soft | Crisp | Smooth\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__suvarnayandapalli__fruit-classification-data/fruit.csv"]}
{"id": "kaggle__suvarnayandapalli__fruit-classification-data__1", "question": "I have a database of Fruit classification data. As a dietitian, I want to evaluate the calorie content and portion sizes of different fruits for meal planning.", "description": "\n\nFruit classification data\n\nfruit\n49 rows x 6 columns\n1. id | int64 | 1 | 2 | 3 | 4 | 5\n2. fruit_name | object | Apple | Orange | Banana | Apple | Orange\n3. color | object | Red | Orange | Yellow | Green | Orange\n4. diameter | float64 | 7.6 | 7.2 | 6.8 | 7.5 | 7.0\n5. weight | float64 | 150.0 | 180.0 | 120.0 | 155.0 | 175.0\n6. texture | object | Crisp | Smooth | Soft | Crisp | Smooth\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__suvarnayandapalli__fruit-classification-data/fruit.csv"]}
{"id": "kaggle__suvarnayandapalli__fruit-classification-data__2", "question": "I have a database of Fruit classification data. As a fruit exporter, I want to identify the fruits that meet export standards and have a longer shelf life.", "description": "\n\nFruit classification data\n\nfruit\n49 rows x 6 columns\n1. id | int64 | 1 | 2 | 3 | 4 | 5\n2. fruit_name | object | Apple | Orange | Banana | Apple | Orange\n3. color | object | Red | Orange | Yellow | Green | Orange\n4. diameter | float64 | 7.6 | 7.2 | 6.8 | 7.5 | 7.0\n5. weight | float64 | 150.0 | 180.0 | 120.0 | 155.0 | 175.0\n6. texture | object | Crisp | Smooth | Soft | Crisp | Smooth\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__suvarnayandapalli__fruit-classification-data/fruit.csv"]}
{"id": "kaggle__suvarnayandapalli__fruit-classification-data__3", "question": "I have a database of Fruit classification data. As a consumer, I want to compare the characteristics of fruits to make informed decisions during grocery shopping.", "description": "\n\nFruit classification data\n\nfruit\n49 rows x 6 columns\n1. id | int64 | 1 | 2 | 3 | 4 | 5\n2. fruit_name | object | Apple | Orange | Banana | Apple | Orange\n3. color | object | Red | Orange | Yellow | Green | Orange\n4. diameter | float64 | 7.6 | 7.2 | 6.8 | 7.5 | 7.0\n5. weight | float64 | 150.0 | 180.0 | 120.0 | 155.0 | 175.0\n6. texture | object | Crisp | Smooth | Soft | Crisp | Smooth\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__suvarnayandapalli__fruit-classification-data/fruit.csv"]}
{"id": "kaggle__suvarnayandapalli__fruit-classification-data__4", "question": "I have a database of Fruit classification data. As a researcher, I want to investigate the relationship between fruit characteristics and consumer preferences.", "description": "\n\nFruit classification data\n\nfruit\n49 rows x 6 columns\n1. id | int64 | 1 | 2 | 3 | 4 | 5\n2. fruit_name | object | Apple | Orange | Banana | Apple | Orange\n3. color | object | Red | Orange | Yellow | Green | Orange\n4. diameter | float64 | 7.6 | 7.2 | 6.8 | 7.5 | 7.0\n5. weight | float64 | 150.0 | 180.0 | 120.0 | 155.0 | 175.0\n6. texture | object | Crisp | Smooth | Soft | Crisp | Smooth\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__suvarnayandapalli__fruit-classification-data/fruit.csv"]}
{"id": "kaggle__tanatmetmaolee__nba-player-statistics-2023__0", "question": "I have a database of NBA Player Statistics 2023. As a fantasy league player, I want to select players for my team based on their performance.", "description": "\n\nNBA Player Statistics 2023\n\n2023_nba_player_stats\n534 rows x 30 columns\n1. Player | object | Jayson Tatum | Joel Embiid | Luka Doncic | Shai Gilgeous-Alexander | Giannis Antetokounmpo\n2. POS | object | SF | C | PG | PG | PF\n3. Team | object | BOS | PHI | DAL | OKC | MIL\n4. Age | float64 | 25.0 | 29.0 | 24.0 | 24.0 | 28.0\n5. GP | float64 | 74.0 | 66.0 | 66.0 | 68.0 | 63.0\n6. W | float64 | 52.0 | 43.0 | 33.0 | 33.0 | 47.0\n7. L | float64 | 22.0 | 23.0 | 33.0 | 35.0 | 16.0\n8. Min | float64 | 2732.2 | 2284.1 | 2390.5 | 2416.0 | 2023.6\n9. PTS | float64 | 2225.0 | 2183.0 | 2138.0 | 2135.0 | 1959.0\n10. FGM | float64 | 727.0 | 728.0 | 719.0 | 704.0 | 707.0\n11. FGA | float64 | 1559.0 | 1328.0 | 1449.0 | 1381.0 | 1278.0\n12. FG% | float64 | 46.6 | 54.8 | 49.6 | 51.0 | 55.3\n13. 3PM | float64 | 240.0 | 66.0 | 185.0 | 58.0 | 47.0\n14. 3PA | float64 | 686.0 | 200.0 | 541.0 | 168.0 | 171.0\n15. 3P% | float64 | 35.0 | 33.0 | 34.2 | 34.5 | 27.5\n16. FTM | float64 | 531.0 | 661.0 | 515.0 | 669.0 | 498.0\n17. FTA | float64 | 622.0 | 771.0 | 694.0 | 739.0 | 772.0\n18. FT% | float64 | 85.4 | 85.7 | 74.2 | 90.5 | 64.5\n19. OREB | float64 | 78.0 | 113.0 | 54.0 | 59.0 | 137.0\n20. DREB | float64 | 571.0 | 557.0 | 515.0 | 270.0 | 605.0\n21. REB | float64 | 649.0 | 670.0 | 569.0 | 329.0 | 742.0\n22. AST | float64 | 342.0 | 274.0 | 529.0 | 371.0 | 359.0\n23. TOV | float64 | 213.0 | 226.0 | 236.0 | 192.0 | 246.0\n24. STL | float64 | 78.0 | 66.0 | 90.0 | 112.0 | 52.0\n25. BLK | float64 | 51.0 | 112.0 | 33.0 | 65.0 | 51.0\n26. PF | float64 | 160.0 | 205.0 | 166.0 | 192.0 | 197.0\n27. FP | float64 | 3691.0 | 3706.0 | 3747.0 | 3425.0 | 3451.0\n28. DD2 | float64 | 31.0 | 39.0 | 36.0 | 3.0 | 46.0\n29. TD3 | float64 | 1.0 | 1.0 | 10.0 | 0.0 | 6.0\n30. +/- | float64 | 470.0 | 424.0 | 128.0 | 149.0 | 341.0\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__tanatmetmaolee__nba-player-statistics-2023/2023_nba_player_stats.csv"]}
{"id": "kaggle__tanatmetmaolee__nba-player-statistics-2023__1", "question": "I have a database of NBA Player Statistics 2023. As a school counselor or coach, I want to advise student-athletes on their career prospects in basketball.", "description": "\n\nNBA Player Statistics 2023\n\n2023_nba_player_stats\n534 rows x 30 columns\n1. Player | object | Jayson Tatum | Joel Embiid | Luka Doncic | Shai Gilgeous-Alexander | Giannis Antetokounmpo\n2. POS | object | SF | C | PG | PG | PF\n3. Team | object | BOS | PHI | DAL | OKC | MIL\n4. Age | float64 | 25.0 | 29.0 | 24.0 | 24.0 | 28.0\n5. GP | float64 | 74.0 | 66.0 | 66.0 | 68.0 | 63.0\n6. W | float64 | 52.0 | 43.0 | 33.0 | 33.0 | 47.0\n7. L | float64 | 22.0 | 23.0 | 33.0 | 35.0 | 16.0\n8. Min | float64 | 2732.2 | 2284.1 | 2390.5 | 2416.0 | 2023.6\n9. PTS | float64 | 2225.0 | 2183.0 | 2138.0 | 2135.0 | 1959.0\n10. FGM | float64 | 727.0 | 728.0 | 719.0 | 704.0 | 707.0\n11. FGA | float64 | 1559.0 | 1328.0 | 1449.0 | 1381.0 | 1278.0\n12. FG% | float64 | 46.6 | 54.8 | 49.6 | 51.0 | 55.3\n13. 3PM | float64 | 240.0 | 66.0 | 185.0 | 58.0 | 47.0\n14. 3PA | float64 | 686.0 | 200.0 | 541.0 | 168.0 | 171.0\n15. 3P% | float64 | 35.0 | 33.0 | 34.2 | 34.5 | 27.5\n16. FTM | float64 | 531.0 | 661.0 | 515.0 | 669.0 | 498.0\n17. FTA | float64 | 622.0 | 771.0 | 694.0 | 739.0 | 772.0\n18. FT% | float64 | 85.4 | 85.7 | 74.2 | 90.5 | 64.5\n19. OREB | float64 | 78.0 | 113.0 | 54.0 | 59.0 | 137.0\n20. DREB | float64 | 571.0 | 557.0 | 515.0 | 270.0 | 605.0\n21. REB | float64 | 649.0 | 670.0 | 569.0 | 329.0 | 742.0\n22. AST | float64 | 342.0 | 274.0 | 529.0 | 371.0 | 359.0\n23. TOV | float64 | 213.0 | 226.0 | 236.0 | 192.0 | 246.0\n24. STL | float64 | 78.0 | 66.0 | 90.0 | 112.0 | 52.0\n25. BLK | float64 | 51.0 | 112.0 | 33.0 | 65.0 | 51.0\n26. PF | float64 | 160.0 | 205.0 | 166.0 | 192.0 | 197.0\n27. FP | float64 | 3691.0 | 3706.0 | 3747.0 | 3425.0 | 3451.0\n28. DD2 | float64 | 31.0 | 39.0 | 36.0 | 3.0 | 46.0\n29. TD3 | float64 | 1.0 | 1.0 | 10.0 | 0.0 | 6.0\n30. +/- | float64 | 470.0 | 424.0 | 128.0 | 149.0 | 341.0\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__tanatmetmaolee__nba-player-statistics-2023/2023_nba_player_stats.csv"]}
{"id": "kaggle__yasserh__uber-fares-dataset__0", "question": "I have a database of Uber Fares Dataset. As a business owner, I want to analyze the fares to determine the profitability of using Uber for transportation needs.", "description": "\n\nUber Fares Dataset\n\nuber\n10000 rows x 9 columns\n1. Unnamed: 0 | int64 | 24238194 | 55085966 | 51671648 | 48399259 | 29152955\n2. key | object | 2015-05-07 19:52:06.0000003 | 2014-02-18 14:26:00.00000070 | 2010-04-01 14:42:00.000000160 | 2015-06-17 17:52:03.0000007 | 2015-05-28 13:31:03.0000006\n3. fare_amount | float64 | 7.5 | 10.5 | 15.7 | 9.0 | 11.0\n4. pickup_datetime | object | 2015-05-07 19:52:06 UTC | 2014-02-18 14:26:00 UTC | 2010-04-01 14:42:00 UTC | 2015-06-17 17:52:03 UTC | 2015-05-28 13:31:03 UTC\n5. pickup_longitude | float64 | -73.99981689453125 | -73.98002199999999 | -73.97336 | -73.97213745117188 | -73.96671295166014\n6. pickup_latitude | float64 | 40.73835372924805 | 40.74599 | 40.786952 | 40.7498893737793 | 40.80403518676758\n7. dropoff_longitude | float64 | -73.99951171875 | -74.00343199999999 | -73.97281 | -73.98185729980467 | -73.93840026855469\n8. dropoff_latitude | float64 | 40.72321701049805 | 40.759667 | 40.743548 | 40.73242568969727 | 40.79726791381836\n9. passenger_count | int64 | 1 | 1 | 1 | 1 | 1\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__yasserh__uber-fares-dataset/uber.csv"]}
{"id": "kaggle__yasserh__uber-fares-dataset__1", "question": "I have a database of Uber Fares Dataset. As a transportation planner, I want to assess the fare data to determine the feasibility of implementing Uber as a transportation option in a city.", "description": "\n\nUber Fares Dataset\n\nuber\n10000 rows x 9 columns\n1. Unnamed: 0 | int64 | 24238194 | 55085966 | 51671648 | 48399259 | 29152955\n2. key | object | 2015-05-07 19:52:06.0000003 | 2014-02-18 14:26:00.00000070 | 2010-04-01 14:42:00.000000160 | 2015-06-17 17:52:03.0000007 | 2015-05-28 13:31:03.0000006\n3. fare_amount | float64 | 7.5 | 10.5 | 15.7 | 9.0 | 11.0\n4. pickup_datetime | object | 2015-05-07 19:52:06 UTC | 2014-02-18 14:26:00 UTC | 2010-04-01 14:42:00 UTC | 2015-06-17 17:52:03 UTC | 2015-05-28 13:31:03 UTC\n5. pickup_longitude | float64 | -73.99981689453125 | -73.98002199999999 | -73.97336 | -73.97213745117188 | -73.96671295166014\n6. pickup_latitude | float64 | 40.73835372924805 | 40.74599 | 40.786952 | 40.7498893737793 | 40.80403518676758\n7. dropoff_longitude | float64 | -73.99951171875 | -74.00343199999999 | -73.97281 | -73.98185729980467 | -73.93840026855469\n8. dropoff_latitude | float64 | 40.72321701049805 | 40.759667 | 40.743548 | 40.73242568969727 | 40.79726791381836\n9. passenger_count | int64 | 1 | 1 | 1 | 1 | 1\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__yasserh__uber-fares-dataset/uber.csv"]}
{"id": "kaggle__yasserh__uber-fares-dataset__2", "question": "I have a database of Uber Fares Dataset. As a government official, I want to review the fare information to make decisions regarding regulations and policies related to Uber.", "description": "\n\nUber Fares Dataset\n\nuber\n10000 rows x 9 columns\n1. Unnamed: 0 | int64 | 24238194 | 55085966 | 51671648 | 48399259 | 29152955\n2. key | object | 2015-05-07 19:52:06.0000003 | 2014-02-18 14:26:00.00000070 | 2010-04-01 14:42:00.000000160 | 2015-06-17 17:52:03.0000007 | 2015-05-28 13:31:03.0000006\n3. fare_amount | float64 | 7.5 | 10.5 | 15.7 | 9.0 | 11.0\n4. pickup_datetime | object | 2015-05-07 19:52:06 UTC | 2014-02-18 14:26:00 UTC | 2010-04-01 14:42:00 UTC | 2015-06-17 17:52:03 UTC | 2015-05-28 13:31:03 UTC\n5. pickup_longitude | float64 | -73.99981689453125 | -73.98002199999999 | -73.97336 | -73.97213745117188 | -73.96671295166014\n6. pickup_latitude | float64 | 40.73835372924805 | 40.74599 | 40.786952 | 40.7498893737793 | 40.80403518676758\n7. dropoff_longitude | float64 | -73.99951171875 | -74.00343199999999 | -73.97281 | -73.98185729980467 | -73.93840026855469\n8. dropoff_latitude | float64 | 40.72321701049805 | 40.759667 | 40.743548 | 40.73242568969727 | 40.79726791381836\n9. passenger_count | int64 | 1 | 1 | 1 | 1 | 1\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__yasserh__uber-fares-dataset/uber.csv"]}
{"id": "kaggle__yasserh__uber-fares-dataset__3", "question": "I have a database of Uber Fares Dataset. As a financial analyst, I want to analyze the fare information to evaluate the financial performance of Uber and make investment recommendations.", "description": "\n\nUber Fares Dataset\n\nuber\n10000 rows x 9 columns\n1. Unnamed: 0 | int64 | 24238194 | 55085966 | 51671648 | 48399259 | 29152955\n2. key | object | 2015-05-07 19:52:06.0000003 | 2014-02-18 14:26:00.00000070 | 2010-04-01 14:42:00.000000160 | 2015-06-17 17:52:03.0000007 | 2015-05-28 13:31:03.0000006\n3. fare_amount | float64 | 7.5 | 10.5 | 15.7 | 9.0 | 11.0\n4. pickup_datetime | object | 2015-05-07 19:52:06 UTC | 2014-02-18 14:26:00 UTC | 2010-04-01 14:42:00 UTC | 2015-06-17 17:52:03 UTC | 2015-05-28 13:31:03 UTC\n5. pickup_longitude | float64 | -73.99981689453125 | -73.98002199999999 | -73.97336 | -73.97213745117188 | -73.96671295166014\n6. pickup_latitude | float64 | 40.73835372924805 | 40.74599 | 40.786952 | 40.7498893737793 | 40.80403518676758\n7. dropoff_longitude | float64 | -73.99951171875 | -74.00343199999999 | -73.97281 | -73.98185729980467 | -73.93840026855469\n8. dropoff_latitude | float64 | 40.72321701049805 | 40.759667 | 40.743548 | 40.73242568969727 | 40.79726791381836\n9. passenger_count | int64 | 1 | 1 | 1 | 1 | 1\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__yasserh__uber-fares-dataset/uber.csv"]}
{"id": "kaggle__yasserh__uber-fares-dataset__4", "question": "I have a database of Uber Fares Dataset. As a consumer advocate, I want to analyze the fare data to assess if Uber is providing fair pricing to customers.", "description": "\n\nUber Fares Dataset\n\nuber\n10000 rows x 9 columns\n1. Unnamed: 0 | int64 | 24238194 | 55085966 | 51671648 | 48399259 | 29152955\n2. key | object | 2015-05-07 19:52:06.0000003 | 2014-02-18 14:26:00.00000070 | 2010-04-01 14:42:00.000000160 | 2015-06-17 17:52:03.0000007 | 2015-05-28 13:31:03.0000006\n3. fare_amount | float64 | 7.5 | 10.5 | 15.7 | 9.0 | 11.0\n4. pickup_datetime | object | 2015-05-07 19:52:06 UTC | 2014-02-18 14:26:00 UTC | 2010-04-01 14:42:00 UTC | 2015-06-17 17:52:03 UTC | 2015-05-28 13:31:03 UTC\n5. pickup_longitude | float64 | -73.99981689453125 | -73.98002199999999 | -73.97336 | -73.97213745117188 | -73.96671295166014\n6. pickup_latitude | float64 | 40.73835372924805 | 40.74599 | 40.786952 | 40.7498893737793 | 40.80403518676758\n7. dropoff_longitude | float64 | -73.99951171875 | -74.00343199999999 | -73.97281 | -73.98185729980467 | -73.93840026855469\n8. dropoff_latitude | float64 | 40.72321701049805 | 40.759667 | 40.743548 | 40.73242568969727 | 40.79726791381836\n9. passenger_count | int64 | 1 | 1 | 1 | 1 | 1\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__yasserh__uber-fares-dataset/uber.csv"]}
{"id": "kaggle__yasserh__uber-fares-dataset__5", "question": "I have a database of Uber Fares Dataset. As a data scientist, I want to explore the fare data to develop predictive models for estimating future fares.", "description": "\n\nUber Fares Dataset\n\nuber\n10000 rows x 9 columns\n1. Unnamed: 0 | int64 | 24238194 | 55085966 | 51671648 | 48399259 | 29152955\n2. key | object | 2015-05-07 19:52:06.0000003 | 2014-02-18 14:26:00.00000070 | 2010-04-01 14:42:00.000000160 | 2015-06-17 17:52:03.0000007 | 2015-05-28 13:31:03.0000006\n3. fare_amount | float64 | 7.5 | 10.5 | 15.7 | 9.0 | 11.0\n4. pickup_datetime | object | 2015-05-07 19:52:06 UTC | 2014-02-18 14:26:00 UTC | 2010-04-01 14:42:00 UTC | 2015-06-17 17:52:03 UTC | 2015-05-28 13:31:03 UTC\n5. pickup_longitude | float64 | -73.99981689453125 | -73.98002199999999 | -73.97336 | -73.97213745117188 | -73.96671295166014\n6. pickup_latitude | float64 | 40.73835372924805 | 40.74599 | 40.786952 | 40.7498893737793 | 40.80403518676758\n7. dropoff_longitude | float64 | -73.99951171875 | -74.00343199999999 | -73.97281 | -73.98185729980467 | -73.93840026855469\n8. dropoff_latitude | float64 | 40.72321701049805 | 40.759667 | 40.743548 | 40.73242568969727 | 40.79726791381836\n9. passenger_count | int64 | 1 | 1 | 1 | 1 | 1\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__yasserh__uber-fares-dataset/uber.csv"]}
{"id": "kaggle__yasserh__uber-fares-dataset__6", "question": "I have a database of Uber Fares Dataset. As a ride-hailing driver, I want to analyze the fares to assess my income potential and optimize my strategy for picking up passengers.", "description": "\n\nUber Fares Dataset\n\nuber\n10000 rows x 9 columns\n1. Unnamed: 0 | int64 | 24238194 | 55085966 | 51671648 | 48399259 | 29152955\n2. key | object | 2015-05-07 19:52:06.0000003 | 2014-02-18 14:26:00.00000070 | 2010-04-01 14:42:00.000000160 | 2015-06-17 17:52:03.0000007 | 2015-05-28 13:31:03.0000006\n3. fare_amount | float64 | 7.5 | 10.5 | 15.7 | 9.0 | 11.0\n4. pickup_datetime | object | 2015-05-07 19:52:06 UTC | 2014-02-18 14:26:00 UTC | 2010-04-01 14:42:00 UTC | 2015-06-17 17:52:03 UTC | 2015-05-28 13:31:03 UTC\n5. pickup_longitude | float64 | -73.99981689453125 | -73.98002199999999 | -73.97336 | -73.97213745117188 | -73.96671295166014\n6. pickup_latitude | float64 | 40.73835372924805 | 40.74599 | 40.786952 | 40.7498893737793 | 40.80403518676758\n7. dropoff_longitude | float64 | -73.99951171875 | -74.00343199999999 | -73.97281 | -73.98185729980467 | -73.93840026855469\n8. dropoff_latitude | float64 | 40.72321701049805 | 40.759667 | 40.743548 | 40.73242568969727 | 40.79726791381836\n9. passenger_count | int64 | 1 | 1 | 1 | 1 | 1\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__yasserh__uber-fares-dataset/uber.csv"]}
{"id": "kaggle__bhanuprasanna527__stock-market-prediction__1", "question": "I have a database of IBM - Real Time Stock Analysis. As a risk manager, I want to assess the risks associated with investing in IBM stocks and make decisions based on historical performance and trends.", "description": "\n\nIBM - Real Time Stock Analysis\n\n2 Year IBM Stock Data\n10328 rows x 6 columns\n1. time | object | 3/25/2022 19:19 | 3/25/2022 15:49 | 3/25/2022 15:28 | 3/25/2022 15:07 | 3/25/2022 14:46\n2. open | float64 | 131.3 | 131.09 | 130.76 | 130.92 | 131.07\n3. high | float64 | 131.3 | 131.13 | 130.76 | 130.93 | 131.077\n4. low | float64 | 131.3 | 131.09 | 130.7 | 130.88 | 131.05\n5. close | float64 | 131.3 | 131.1 | 130.759 | 130.88 | 131.05\n6. volume | int64 | 718 | 21925 | 11293 | 7104 | 5125\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__bhanuprasanna527__stock-market-prediction/2 Year IBM Stock Data.csv"]}
{"id": "kaggle__bhanuprasanna527__stock-market-prediction__2", "question": "I have a database of IBM - Real Time Stock Analysis. As a financial journalist, I want to analyze the IBM stock data to write articles about the stock's performance and trends.", "description": "\n\nIBM - Real Time Stock Analysis\n\n2 Year IBM Stock Data\n10328 rows x 6 columns\n1. time | object | 3/25/2022 19:19 | 3/25/2022 15:49 | 3/25/2022 15:28 | 3/25/2022 15:07 | 3/25/2022 14:46\n2. open | float64 | 131.3 | 131.09 | 130.76 | 130.92 | 131.07\n3. high | float64 | 131.3 | 131.13 | 130.76 | 130.93 | 131.077\n4. low | float64 | 131.3 | 131.09 | 130.7 | 130.88 | 131.05\n5. close | float64 | 131.3 | 131.1 | 130.759 | 130.88 | 131.05\n6. volume | int64 | 718 | 21925 | 11293 | 7104 | 5125\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__bhanuprasanna527__stock-market-prediction/2 Year IBM Stock Data.csv"]}
{"id": "kaggle__bhanuprasanna527__stock-market-prediction__3", "question": "I have a database of IBM - Real Time Stock Analysis. As a shareholder, I want to monitor and make informed decisions about my IBM stock investments based on the stock's performance in the past two years.", "description": "\n\nIBM - Real Time Stock Analysis\n\n2 Year IBM Stock Data\n10328 rows x 6 columns\n1. time | object | 3/25/2022 19:19 | 3/25/2022 15:49 | 3/25/2022 15:28 | 3/25/2022 15:07 | 3/25/2022 14:46\n2. open | float64 | 131.3 | 131.09 | 130.76 | 130.92 | 131.07\n3. high | float64 | 131.3 | 131.13 | 130.76 | 130.93 | 131.077\n4. low | float64 | 131.3 | 131.09 | 130.7 | 130.88 | 131.05\n5. close | float64 | 131.3 | 131.1 | 130.759 | 130.88 | 131.05\n6. volume | int64 | 718 | 21925 | 11293 | 7104 | 5125\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__bhanuprasanna527__stock-market-prediction/2 Year IBM Stock Data.csv"]}
{"id": "kaggle__bhanuprasanna527__stock-market-prediction__4", "question": "I have a database of IBM - Real Time Stock Analysis. As a board member, I want to review the IBM stock data to make informed decisions about the future direction and strategy of the company.", "description": "\n\nIBM - Real Time Stock Analysis\n\n2 Year IBM Stock Data\n10328 rows x 6 columns\n1. time | object | 3/25/2022 19:19 | 3/25/2022 15:49 | 3/25/2022 15:28 | 3/25/2022 15:07 | 3/25/2022 14:46\n2. open | float64 | 131.3 | 131.09 | 130.76 | 130.92 | 131.07\n3. high | float64 | 131.3 | 131.13 | 130.76 | 130.93 | 131.077\n4. low | float64 | 131.3 | 131.09 | 130.7 | 130.88 | 131.05\n5. close | float64 | 131.3 | 131.1 | 130.759 | 130.88 | 131.05\n6. volume | int64 | 718 | 21925 | 11293 | 7104 | 5125\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__bhanuprasanna527__stock-market-prediction/2 Year IBM Stock Data.csv"]}
{"id": "kaggle__igorcoelho24__pokemon-all-generations__0", "question": "I have a database of Pokemon All Generations. As a game developer, I want to balance the stats of different Pokemon to ensure fair gameplay.", "description": "\n\nPokemon All Generations\n\nPokemon_full\n890 rows x 11 columns\n1. name | object | bulbasaur | ivysaur | venusaur | charmander | charmeleon\n2. pokedex id | int64 | 1 | 2 | 3 | 4 | 5\n3. height | int64 | 7 | 10 | 20 | 6 | 11\n4. weight | int64 | 69 | 130 | 1000 | 85 | 190\n5. type | object | grass | grass | grass | fire | fire\n6. hp | int64 | 45 | 60 | 80 | 39 | 58\n7. attack | int64 | 49 | 62 | 82 | 52 | 64\n8. defense | int64 | 49 | 63 | 83 | 43 | 58\n9. sp atk | int64 | 65 | 80 | 100 | 60 | 80\n10. sp def | int64 | 65 | 80 | 100 | 50 | 65\n11. speed | int64 | 45 | 60 | 80 | 65 | 80\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__igorcoelho24__pokemon-all-generations/Pokemon_full.csv"]}
{"id": "kaggle__igorcoelho24__pokemon-all-generations__1", "question": "I have a database of Pokemon All Generations. As a marketing manager, I want to select the most popular Pokemon for promotional campaigns.", "description": "\n\nPokemon All Generations\n\nPokemon_full\n890 rows x 11 columns\n1. name | object | bulbasaur | ivysaur | venusaur | charmander | charmeleon\n2. pokedex id | int64 | 1 | 2 | 3 | 4 | 5\n3. height | int64 | 7 | 10 | 20 | 6 | 11\n4. weight | int64 | 69 | 130 | 1000 | 85 | 190\n5. type | object | grass | grass | grass | fire | fire\n6. hp | int64 | 45 | 60 | 80 | 39 | 58\n7. attack | int64 | 49 | 62 | 82 | 52 | 64\n8. defense | int64 | 49 | 63 | 83 | 43 | 58\n9. sp atk | int64 | 65 | 80 | 100 | 60 | 80\n10. sp def | int64 | 65 | 80 | 100 | 50 | 65\n11. speed | int64 | 45 | 60 | 80 | 65 | 80\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__igorcoelho24__pokemon-all-generations/Pokemon_full.csv"]}
{"id": "kaggle__igorcoelho24__pokemon-all-generations__2", "question": "I have a database of Pokemon All Generations. As a competitive player, I want to analyze Pokemon stats to build the best team for battles.", "description": "\n\nPokemon All Generations\n\nPokemon_full\n890 rows x 11 columns\n1. name | object | bulbasaur | ivysaur | venusaur | charmander | charmeleon\n2. pokedex id | int64 | 1 | 2 | 3 | 4 | 5\n3. height | int64 | 7 | 10 | 20 | 6 | 11\n4. weight | int64 | 69 | 130 | 1000 | 85 | 190\n5. type | object | grass | grass | grass | fire | fire\n6. hp | int64 | 45 | 60 | 80 | 39 | 58\n7. attack | int64 | 49 | 62 | 82 | 52 | 64\n8. defense | int64 | 49 | 63 | 83 | 43 | 58\n9. sp atk | int64 | 65 | 80 | 100 | 60 | 80\n10. sp def | int64 | 65 | 80 | 100 | 50 | 65\n11. speed | int64 | 45 | 60 | 80 | 65 | 80\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__igorcoelho24__pokemon-all-generations/Pokemon_full.csv"]}
{"id": "kaggle__igorcoelho24__pokemon-all-generations__4", "question": "I have a database of Pokemon All Generations. As a designer, I want to create merchandise based on the most iconic Pokemon.", "description": "\n\nPokemon All Generations\n\nPokemon_full\n890 rows x 11 columns\n1. name | object | bulbasaur | ivysaur | venusaur | charmander | charmeleon\n2. pokedex id | int64 | 1 | 2 | 3 | 4 | 5\n3. height | int64 | 7 | 10 | 20 | 6 | 11\n4. weight | int64 | 69 | 130 | 1000 | 85 | 190\n5. type | object | grass | grass | grass | fire | fire\n6. hp | int64 | 45 | 60 | 80 | 39 | 58\n7. attack | int64 | 49 | 62 | 82 | 52 | 64\n8. defense | int64 | 49 | 63 | 83 | 43 | 58\n9. sp atk | int64 | 65 | 80 | 100 | 60 | 80\n10. sp def | int64 | 65 | 80 | 100 | 50 | 65\n11. speed | int64 | 45 | 60 | 80 | 65 | 80\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__igorcoelho24__pokemon-all-generations/Pokemon_full.csv"]}
{"id": "kaggle__igorcoelho24__pokemon-all-generations__5", "question": "I have a database of Pokemon All Generations. As a collector, I want to identify rare and valuable Pokemon for my collection.", "description": "\n\nPokemon All Generations\n\nPokemon_full\n890 rows x 11 columns\n1. name | object | bulbasaur | ivysaur | venusaur | charmander | charmeleon\n2. pokedex id | int64 | 1 | 2 | 3 | 4 | 5\n3. height | int64 | 7 | 10 | 20 | 6 | 11\n4. weight | int64 | 69 | 130 | 1000 | 85 | 190\n5. type | object | grass | grass | grass | fire | fire\n6. hp | int64 | 45 | 60 | 80 | 39 | 58\n7. attack | int64 | 49 | 62 | 82 | 52 | 64\n8. defense | int64 | 49 | 63 | 83 | 43 | 58\n9. sp atk | int64 | 65 | 80 | 100 | 60 | 80\n10. sp def | int64 | 65 | 80 | 100 | 50 | 65\n11. speed | int64 | 45 | 60 | 80 | 65 | 80\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__igorcoelho24__pokemon-all-generations/Pokemon_full.csv"]}
{"id": "kaggle__igorcoelho24__pokemon-all-generations__6", "question": "I have a database of Pokemon All Generations. As a professor, I want to analyze the distribution of different Pokemon types across regions.", "description": "\n\nPokemon All Generations\n\nPokemon_full\n890 rows x 11 columns\n1. name | object | bulbasaur | ivysaur | venusaur | charmander | charmeleon\n2. pokedex id | int64 | 1 | 2 | 3 | 4 | 5\n3. height | int64 | 7 | 10 | 20 | 6 | 11\n4. weight | int64 | 69 | 130 | 1000 | 85 | 190\n5. type | object | grass | grass | grass | fire | fire\n6. hp | int64 | 45 | 60 | 80 | 39 | 58\n7. attack | int64 | 49 | 62 | 82 | 52 | 64\n8. defense | int64 | 49 | 63 | 83 | 43 | 58\n9. sp atk | int64 | 65 | 80 | 100 | 60 | 80\n10. sp def | int64 | 65 | 80 | 100 | 50 | 65\n11. speed | int64 | 45 | 60 | 80 | 65 | 80\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__igorcoelho24__pokemon-all-generations/Pokemon_full.csv"]}
{"id": "kaggle__igorcoelho24__pokemon-all-generations__7", "question": "I have a database of Pokemon All Generations. As a strategist, I want to develop effective battle tactics by studying the strengths and weaknesses of different Pokemon.", "description": "\n\nPokemon All Generations\n\nPokemon_full\n890 rows x 11 columns\n1. name | object | bulbasaur | ivysaur | venusaur | charmander | charmeleon\n2. pokedex id | int64 | 1 | 2 | 3 | 4 | 5\n3. height | int64 | 7 | 10 | 20 | 6 | 11\n4. weight | int64 | 69 | 130 | 1000 | 85 | 190\n5. type | object | grass | grass | grass | fire | fire\n6. hp | int64 | 45 | 60 | 80 | 39 | 58\n7. attack | int64 | 49 | 62 | 82 | 52 | 64\n8. defense | int64 | 49 | 63 | 83 | 43 | 58\n9. sp atk | int64 | 65 | 80 | 100 | 60 | 80\n10. sp def | int64 | 65 | 80 | 100 | 50 | 65\n11. speed | int64 | 45 | 60 | 80 | 65 | 80\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__igorcoelho24__pokemon-all-generations/Pokemon_full.csv"]}
{"id": "kaggle__igorcoelho24__pokemon-all-generations__8", "question": "I have a database of Pokemon All Generations. As a content creator, I want to select diverse Pokemon for a well-rounded gameplay experience.", "description": "\n\nPokemon All Generations\n\nPokemon_full\n890 rows x 11 columns\n1. name | object | bulbasaur | ivysaur | venusaur | charmander | charmeleon\n2. pokedex id | int64 | 1 | 2 | 3 | 4 | 5\n3. height | int64 | 7 | 10 | 20 | 6 | 11\n4. weight | int64 | 69 | 130 | 1000 | 85 | 190\n5. type | object | grass | grass | grass | fire | fire\n6. hp | int64 | 45 | 60 | 80 | 39 | 58\n7. attack | int64 | 49 | 62 | 82 | 52 | 64\n8. defense | int64 | 49 | 63 | 83 | 43 | 58\n9. sp atk | int64 | 65 | 80 | 100 | 60 | 80\n10. sp def | int64 | 65 | 80 | 100 | 50 | 65\n11. speed | int64 | 45 | 60 | 80 | 65 | 80\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__igorcoelho24__pokemon-all-generations/Pokemon_full.csv"]}
{"id": "kaggle__igorcoelho24__pokemon-all-generations__9", "question": "I have a database of Pokemon All Generations. As a fan community manager, I want to organize events or competitions based on specific Pokemon characteristics or types.", "description": "\n\nPokemon All Generations\n\nPokemon_full\n890 rows x 11 columns\n1. name | object | bulbasaur | ivysaur | venusaur | charmander | charmeleon\n2. pokedex id | int64 | 1 | 2 | 3 | 4 | 5\n3. height | int64 | 7 | 10 | 20 | 6 | 11\n4. weight | int64 | 69 | 130 | 1000 | 85 | 190\n5. type | object | grass | grass | grass | fire | fire\n6. hp | int64 | 45 | 60 | 80 | 39 | 58\n7. attack | int64 | 49 | 62 | 82 | 52 | 64\n8. defense | int64 | 49 | 63 | 83 | 43 | 58\n9. sp atk | int64 | 65 | 80 | 100 | 60 | 80\n10. sp def | int64 | 65 | 80 | 100 | 50 | 65\n11. speed | int64 | 45 | 60 | 80 | 65 | 80\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__igorcoelho24__pokemon-all-generations/Pokemon_full.csv"]}
{"id": "kaggle__warcoder__dog-breeds-details__0", "question": "I have a database of Dog breeds details. As a dog breeder, I want to decide which breeds to mate based on specific characteristics.", "description": "\n\nDog breeds details\n\ndog_breeds\n97 rows x 23 columns\n1. Name | object | Golden Retriever | Dachshund | Labrador Retriever | Great Dane | Boxer\n2. min_life_expectancy | int64 | 10 | 12 | 10 | 7 | 10\n3. max_life_expectancy | int64 | 12 | 16 | 12 | 10 | 12\n4. max_height_male | float64 | 24.0 | 9.0 | 24.5 | 32.0 | 25.0\n5. max_height_female | float64 | 24.0 | 9.0 | 24.5 | 32.0 | 25.0\n6. max_weight_male | float64 | 75.0 | 32.0 | 80.0 | 175.0 | 80.0\n7. max_weight_female | float64 | 65.0 | 32.0 | 70.0 | 140.0 | 65.0\n8. min_height_male | float64 | 23.0 | 8.0 | 22.5 | 30.0 | 23.0\n9. min_height_female | float64 | 23.0 | 8.0 | 22.5 | 30.0 | 23.0\n10. min_weight_male | float64 | 65.0 | 16.0 | 65.0 | 140.0 | 65.0\n11. min_weight_female | float64 | 55.0 | 16.0 | 55.0 | 110.0 | 50.0\n12. good_with_children | int64 | 5 | 3 | 5 | 3 | 5\n13. good_with_other_dogs | int64 | 5 | 4 | 5 | 3 | 3\n14. shedding | int64 | 4 | 2 | 4 | 3 | 2\n15. grooming | int64 | 2 | 2 | 2 | 1 | 2\n16. drooling | int64 | 2 | 2 | 2 | 4 | 3\n17. coat_length | int64 | 1 | 2 | 1 | 1 | 1\n18. good_with_strangers | int64 | 5 | 4 | 5 | 3 | 4\n19. playfulness | int64 | 4 | 4 | 5 | 4 | 4\n20. protectiveness | int64 | 3 | 4 | 3 | 5 | 4\n21. trainability | int64 | 5 | 4 | 5 | 3 | 4\n22. energy | int64 | 3 | 3 | 5 | 4 | 4\n23. barking | int64 | 1 | 5 | 3 | 3 | 3\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__warcoder__dog-breeds-details/dog_breeds.csv"]}
{"id": "kaggle__warcoder__dog-breeds-details__1", "question": "I have a database of Dog breeds details. As a dog trainer, I want to determine which breeds are more trainable for different types of training programs.", "description": "\n\nDog breeds details\n\ndog_breeds\n97 rows x 23 columns\n1. Name | object | Golden Retriever | Dachshund | Labrador Retriever | Great Dane | Boxer\n2. min_life_expectancy | int64 | 10 | 12 | 10 | 7 | 10\n3. max_life_expectancy | int64 | 12 | 16 | 12 | 10 | 12\n4. max_height_male | float64 | 24.0 | 9.0 | 24.5 | 32.0 | 25.0\n5. max_height_female | float64 | 24.0 | 9.0 | 24.5 | 32.0 | 25.0\n6. max_weight_male | float64 | 75.0 | 32.0 | 80.0 | 175.0 | 80.0\n7. max_weight_female | float64 | 65.0 | 32.0 | 70.0 | 140.0 | 65.0\n8. min_height_male | float64 | 23.0 | 8.0 | 22.5 | 30.0 | 23.0\n9. min_height_female | float64 | 23.0 | 8.0 | 22.5 | 30.0 | 23.0\n10. min_weight_male | float64 | 65.0 | 16.0 | 65.0 | 140.0 | 65.0\n11. min_weight_female | float64 | 55.0 | 16.0 | 55.0 | 110.0 | 50.0\n12. good_with_children | int64 | 5 | 3 | 5 | 3 | 5\n13. good_with_other_dogs | int64 | 5 | 4 | 5 | 3 | 3\n14. shedding | int64 | 4 | 2 | 4 | 3 | 2\n15. grooming | int64 | 2 | 2 | 2 | 1 | 2\n16. drooling | int64 | 2 | 2 | 2 | 4 | 3\n17. coat_length | int64 | 1 | 2 | 1 | 1 | 1\n18. good_with_strangers | int64 | 5 | 4 | 5 | 3 | 4\n19. playfulness | int64 | 4 | 4 | 5 | 4 | 4\n20. protectiveness | int64 | 3 | 4 | 3 | 5 | 4\n21. trainability | int64 | 5 | 4 | 5 | 3 | 4\n22. energy | int64 | 3 | 3 | 5 | 4 | 4\n23. barking | int64 | 1 | 5 | 3 | 3 | 3\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__warcoder__dog-breeds-details/dog_breeds.csv"]}
{"id": "kaggle__warcoder__dog-breeds-details__2", "question": "I have a database of Dog breeds details. As a dog groomer, I want to recommend appropriate grooming practices based on different coat lengths and shedding levels.", "description": "\n\nDog breeds details\n\ndog_breeds\n97 rows x 23 columns\n1. Name | object | Golden Retriever | Dachshund | Labrador Retriever | Great Dane | Boxer\n2. min_life_expectancy | int64 | 10 | 12 | 10 | 7 | 10\n3. max_life_expectancy | int64 | 12 | 16 | 12 | 10 | 12\n4. max_height_male | float64 | 24.0 | 9.0 | 24.5 | 32.0 | 25.0\n5. max_height_female | float64 | 24.0 | 9.0 | 24.5 | 32.0 | 25.0\n6. max_weight_male | float64 | 75.0 | 32.0 | 80.0 | 175.0 | 80.0\n7. max_weight_female | float64 | 65.0 | 32.0 | 70.0 | 140.0 | 65.0\n8. min_height_male | float64 | 23.0 | 8.0 | 22.5 | 30.0 | 23.0\n9. min_height_female | float64 | 23.0 | 8.0 | 22.5 | 30.0 | 23.0\n10. min_weight_male | float64 | 65.0 | 16.0 | 65.0 | 140.0 | 65.0\n11. min_weight_female | float64 | 55.0 | 16.0 | 55.0 | 110.0 | 50.0\n12. good_with_children | int64 | 5 | 3 | 5 | 3 | 5\n13. good_with_other_dogs | int64 | 5 | 4 | 5 | 3 | 3\n14. shedding | int64 | 4 | 2 | 4 | 3 | 2\n15. grooming | int64 | 2 | 2 | 2 | 1 | 2\n16. drooling | int64 | 2 | 2 | 2 | 4 | 3\n17. coat_length | int64 | 1 | 2 | 1 | 1 | 1\n18. good_with_strangers | int64 | 5 | 4 | 5 | 3 | 4\n19. playfulness | int64 | 4 | 4 | 5 | 4 | 4\n20. protectiveness | int64 | 3 | 4 | 3 | 5 | 4\n21. trainability | int64 | 5 | 4 | 5 | 3 | 4\n22. energy | int64 | 3 | 3 | 5 | 4 | 4\n23. barking | int64 | 1 | 5 | 3 | 3 | 3\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__warcoder__dog-breeds-details/dog_breeds.csv"]}
{"id": "kaggle__warcoder__dog-breeds-details__4", "question": "I have a database of Dog breeds details. As a dog behaviorist, I want to understand the temperament and energy levels of different breeds to provide behavioral advice to dog owners.", "description": "\n\nDog breeds details\n\ndog_breeds\n97 rows x 23 columns\n1. Name | object | Golden Retriever | Dachshund | Labrador Retriever | Great Dane | Boxer\n2. min_life_expectancy | int64 | 10 | 12 | 10 | 7 | 10\n3. max_life_expectancy | int64 | 12 | 16 | 12 | 10 | 12\n4. max_height_male | float64 | 24.0 | 9.0 | 24.5 | 32.0 | 25.0\n5. max_height_female | float64 | 24.0 | 9.0 | 24.5 | 32.0 | 25.0\n6. max_weight_male | float64 | 75.0 | 32.0 | 80.0 | 175.0 | 80.0\n7. max_weight_female | float64 | 65.0 | 32.0 | 70.0 | 140.0 | 65.0\n8. min_height_male | float64 | 23.0 | 8.0 | 22.5 | 30.0 | 23.0\n9. min_height_female | float64 | 23.0 | 8.0 | 22.5 | 30.0 | 23.0\n10. min_weight_male | float64 | 65.0 | 16.0 | 65.0 | 140.0 | 65.0\n11. min_weight_female | float64 | 55.0 | 16.0 | 55.0 | 110.0 | 50.0\n12. good_with_children | int64 | 5 | 3 | 5 | 3 | 5\n13. good_with_other_dogs | int64 | 5 | 4 | 5 | 3 | 3\n14. shedding | int64 | 4 | 2 | 4 | 3 | 2\n15. grooming | int64 | 2 | 2 | 2 | 1 | 2\n16. drooling | int64 | 2 | 2 | 2 | 4 | 3\n17. coat_length | int64 | 1 | 2 | 1 | 1 | 1\n18. good_with_strangers | int64 | 5 | 4 | 5 | 3 | 4\n19. playfulness | int64 | 4 | 4 | 5 | 4 | 4\n20. protectiveness | int64 | 3 | 4 | 3 | 5 | 4\n21. trainability | int64 | 5 | 4 | 5 | 3 | 4\n22. energy | int64 | 3 | 3 | 5 | 4 | 4\n23. barking | int64 | 1 | 5 | 3 | 3 | 3\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__warcoder__dog-breeds-details/dog_breeds.csv"]}
{"id": "kaggle__surajjha101__top-youtube-channels-data__0", "question": "I have a database of Most Subscribed YouTube Channels . As the advertising agency executive, I want to select channels for running ad campaigns.", "description": "\n\nMost Subscribed YouTube Channels \n\nmost_subscribed_youtube_channels\n973 rows x 7 columns\n1. rank | int64 | 1 | 2 | 3 | 4 | 6\n2. Youtuber | object | T-Series | YouTube Movies | Cocomelon - Nursery Rhymes | SET India | PewDiePie\n3. subscribers | object | 222,000,000 | 154,000,000 | 140,000,000 | 139,000,000 | 111,000,000\n4. video views | object | 198,459,090,822 | 0 | 135,481,339,848 | 125,764,252,686 | 28,469,458,228\n5. video count | object | 17,317 | 0 | 786 | 91,271 | 4,497\n6. category | object | Music | Film & Animation | Education | Shows | Gaming\n7. started | int64 | 2006 | 2015 | 2006 | 2006 | 2010\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__surajjha101__top-youtube-channels-data/most_subscribed_youtube_channels.csv"]}
{"id": "kaggle__surajjha101__top-youtube-channels-data__1", "question": "I have a database of Most Subscribed YouTube Channels . As the CEO of a social media analytics company, I want to analyze the data for market research and insights.", "description": "\n\nMost Subscribed YouTube Channels \n\nmost_subscribed_youtube_channels\n973 rows x 7 columns\n1. rank | int64 | 1 | 2 | 3 | 4 | 6\n2. Youtuber | object | T-Series | YouTube Movies | Cocomelon - Nursery Rhymes | SET India | PewDiePie\n3. subscribers | object | 222,000,000 | 154,000,000 | 140,000,000 | 139,000,000 | 111,000,000\n4. video views | object | 198,459,090,822 | 0 | 135,481,339,848 | 125,764,252,686 | 28,469,458,228\n5. video count | object | 17,317 | 0 | 786 | 91,271 | 4,497\n6. category | object | Music | Film & Animation | Education | Shows | Gaming\n7. started | int64 | 2006 | 2015 | 2006 | 2006 | 2010\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__surajjha101__top-youtube-channels-data/most_subscribed_youtube_channels.csv"]}
{"id": "kaggle__surajjha101__top-youtube-channels-data__2", "question": "I have a database of Most Subscribed YouTube Channels . As a media buyer, I want to determine the sponsorship value of different YouTube channels.", "description": "\n\nMost Subscribed YouTube Channels \n\nmost_subscribed_youtube_channels\n973 rows x 7 columns\n1. rank | int64 | 1 | 2 | 3 | 4 | 6\n2. Youtuber | object | T-Series | YouTube Movies | Cocomelon - Nursery Rhymes | SET India | PewDiePie\n3. subscribers | object | 222,000,000 | 154,000,000 | 140,000,000 | 139,000,000 | 111,000,000\n4. video views | object | 198,459,090,822 | 0 | 135,481,339,848 | 125,764,252,686 | 28,469,458,228\n5. video count | object | 17,317 | 0 | 786 | 91,271 | 4,497\n6. category | object | Music | Film & Animation | Education | Shows | Gaming\n7. started | int64 | 2006 | 2015 | 2006 | 2006 | 2010\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__surajjha101__top-youtube-channels-data/most_subscribed_youtube_channels.csv"]}
{"id": "kaggle__surajjha101__top-youtube-channels-data__3", "question": "I have a database of Most Subscribed YouTube Channels . As a YouTube platform representative, I want to analyze the data to identify trends and improve user experience.", "description": "\n\nMost Subscribed YouTube Channels \n\nmost_subscribed_youtube_channels\n973 rows x 7 columns\n1. rank | int64 | 1 | 2 | 3 | 4 | 6\n2. Youtuber | object | T-Series | YouTube Movies | Cocomelon - Nursery Rhymes | SET India | PewDiePie\n3. subscribers | object | 222,000,000 | 154,000,000 | 140,000,000 | 139,000,000 | 111,000,000\n4. video views | object | 198,459,090,822 | 0 | 135,481,339,848 | 125,764,252,686 | 28,469,458,228\n5. video count | object | 17,317 | 0 | 786 | 91,271 | 4,497\n6. category | object | Music | Film & Animation | Education | Shows | Gaming\n7. started | int64 | 2006 | 2015 | 2006 | 2006 | 2010\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__surajjha101__top-youtube-channels-data/most_subscribed_youtube_channels.csv"]}
{"id": "kaggle__surajjha101__top-youtube-channels-data__4", "question": "I have a database of Most Subscribed YouTube Channels . As a brand manager, I want to evaluate the competition and identify potential threats or opportunities.", "description": "\n\nMost Subscribed YouTube Channels \n\nmost_subscribed_youtube_channels\n973 rows x 7 columns\n1. rank | int64 | 1 | 2 | 3 | 4 | 6\n2. Youtuber | object | T-Series | YouTube Movies | Cocomelon - Nursery Rhymes | SET India | PewDiePie\n3. subscribers | object | 222,000,000 | 154,000,000 | 140,000,000 | 139,000,000 | 111,000,000\n4. video views | object | 198,459,090,822 | 0 | 135,481,339,848 | 125,764,252,686 | 28,469,458,228\n5. video count | object | 17,317 | 0 | 786 | 91,271 | 4,497\n6. category | object | Music | Film & Animation | Education | Shows | Gaming\n7. started | int64 | 2006 | 2015 | 2006 | 2006 | 2010\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__surajjha101__top-youtube-channels-data/most_subscribed_youtube_channels.csv"]}
{"id": "kaggle__surajjha101__top-youtube-channels-data__5", "question": "I have a database of Most Subscribed YouTube Channels . As an entertainment industry executive, I want to analyze the data to inform decisions on content acquisition or development.", "description": "\n\nMost Subscribed YouTube Channels \n\nmost_subscribed_youtube_channels\n973 rows x 7 columns\n1. rank | int64 | 1 | 2 | 3 | 4 | 6\n2. Youtuber | object | T-Series | YouTube Movies | Cocomelon - Nursery Rhymes | SET India | PewDiePie\n3. subscribers | object | 222,000,000 | 154,000,000 | 140,000,000 | 139,000,000 | 111,000,000\n4. video views | object | 198,459,090,822 | 0 | 135,481,339,848 | 125,764,252,686 | 28,469,458,228\n5. video count | object | 17,317 | 0 | 786 | 91,271 | 4,497\n6. category | object | Music | Film & Animation | Education | Shows | Gaming\n7. started | int64 | 2006 | 2015 | 2006 | 2006 | 2010\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__surajjha101__top-youtube-channels-data/most_subscribed_youtube_channels.csv"]}
{"id": "kaggle__gsagar12__dspp1__0", "question": "I have a database of Customer Subscription Data. As a product manager, I want to make decisions on product development and pricing.", "description": "\n\nCustomer Subscription Data\n\ncustomer_cases\n10016 rows x 6 columns\n1. Unnamed: 0 | int64 | 1 | 34 | 67 | 100 | 133\n2. case_id | object | CC101 | CC134 | CC167 | CC200 | CC233\n3. date_time | object | 2017-01-01 10:32:03 | 2017-01-02 12:18:54 | 2017-01-03 09:32:44 | 2017-01-03 12:45:09 | 2017-01-04 10:51:56\n4. customer_id | object | C2448 | C2481 | C2514 | C2547 | C2579\n5. channel | object | phone | phone | phone | phone | phone\n6. reason | object | signup | signup | signup | signup | signup\n\ncustomer_info\n10179 rows x 4 columns\n1. Unnamed: 0 | int64 | 1 | 51 | 101 | 151 | 201\n2. customer_id | object | C2448 | C2498 | C2548 | C2598 | C2648\n3. age | int64 | 76 | 59 | 59 | 60 | 33\n4. gender | object | female | female | female | male | male\n\ncustomer_product\n10179 rows x 4 columns\n1. Unnamed: 0 | int64 | 1 | 51 | 101 | 151 | 201\n2. customer_id | object | C2448 | C2498 | C2548 | C2598 | C2648\n3. product | object | prd_1 | prd_1 | prd_1 | prd_1 | prd_1\n4. signup_date_time | object | 2017-01-01 10:35:09 | 2017-01-02 13:40:10 | 2017-01-03 12:51:13 | 2017-01-04 12:30:32 | 2017-01-05 12:07:53\n\nproduct_info\n2 rows x 4 columns\n1. product_id | object | prd_1 | prd_2\n2. name | object | annual_subscription | monthly_subscription\n3. price | int64 | 1200 | 125\n4. billing_cycle | int64 | 12 | 1\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__gsagar12__dspp1/customer_cases.csv", "csv/kaggle__gsagar12__dspp1/customer_info.csv", "csv/kaggle__gsagar12__dspp1/customer_product.csv", "csv/kaggle__gsagar12__dspp1/product_info.csv"]}
{"id": "kaggle__gsagar12__dspp1__1", "question": "I have a database of Customer Subscription Data. As a sales manager, I want to analyze customer subscription data to improve sales performance.", "description": "\n\nCustomer Subscription Data\n\ncustomer_cases\n10016 rows x 6 columns\n1. Unnamed: 0 | int64 | 1 | 34 | 67 | 100 | 133\n2. case_id | object | CC101 | CC134 | CC167 | CC200 | CC233\n3. date_time | object | 2017-01-01 10:32:03 | 2017-01-02 12:18:54 | 2017-01-03 09:32:44 | 2017-01-03 12:45:09 | 2017-01-04 10:51:56\n4. customer_id | object | C2448 | C2481 | C2514 | C2547 | C2579\n5. channel | object | phone | phone | phone | phone | phone\n6. reason | object | signup | signup | signup | signup | signup\n\ncustomer_info\n10179 rows x 4 columns\n1. Unnamed: 0 | int64 | 1 | 51 | 101 | 151 | 201\n2. customer_id | object | C2448 | C2498 | C2548 | C2598 | C2648\n3. age | int64 | 76 | 59 | 59 | 60 | 33\n4. gender | object | female | female | female | male | male\n\ncustomer_product\n10179 rows x 4 columns\n1. Unnamed: 0 | int64 | 1 | 51 | 101 | 151 | 201\n2. customer_id | object | C2448 | C2498 | C2548 | C2598 | C2648\n3. product | object | prd_1 | prd_1 | prd_1 | prd_1 | prd_1\n4. signup_date_time | object | 2017-01-01 10:35:09 | 2017-01-02 13:40:10 | 2017-01-03 12:51:13 | 2017-01-04 12:30:32 | 2017-01-05 12:07:53\n\nproduct_info\n2 rows x 4 columns\n1. product_id | object | prd_1 | prd_2\n2. name | object | annual_subscription | monthly_subscription\n3. price | int64 | 1200 | 125\n4. billing_cycle | int64 | 12 | 1\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__gsagar12__dspp1/customer_cases.csv", "csv/kaggle__gsagar12__dspp1/customer_info.csv", "csv/kaggle__gsagar12__dspp1/customer_product.csv", "csv/kaggle__gsagar12__dspp1/product_info.csv"]}
{"id": "kaggle__gsagar12__dspp1__2", "question": "I have a database of Customer Subscription Data. As a business owner, I want to analyze customer subscription data to identify trends and opportunities.", "description": "\n\nCustomer Subscription Data\n\ncustomer_cases\n10016 rows x 6 columns\n1. Unnamed: 0 | int64 | 1 | 34 | 67 | 100 | 133\n2. case_id | object | CC101 | CC134 | CC167 | CC200 | CC233\n3. date_time | object | 2017-01-01 10:32:03 | 2017-01-02 12:18:54 | 2017-01-03 09:32:44 | 2017-01-03 12:45:09 | 2017-01-04 10:51:56\n4. customer_id | object | C2448 | C2481 | C2514 | C2547 | C2579\n5. channel | object | phone | phone | phone | phone | phone\n6. reason | object | signup | signup | signup | signup | signup\n\ncustomer_info\n10179 rows x 4 columns\n1. Unnamed: 0 | int64 | 1 | 51 | 101 | 151 | 201\n2. customer_id | object | C2448 | C2498 | C2548 | C2598 | C2648\n3. age | int64 | 76 | 59 | 59 | 60 | 33\n4. gender | object | female | female | female | male | male\n\ncustomer_product\n10179 rows x 4 columns\n1. Unnamed: 0 | int64 | 1 | 51 | 101 | 151 | 201\n2. customer_id | object | C2448 | C2498 | C2548 | C2598 | C2648\n3. product | object | prd_1 | prd_1 | prd_1 | prd_1 | prd_1\n4. signup_date_time | object | 2017-01-01 10:35:09 | 2017-01-02 13:40:10 | 2017-01-03 12:51:13 | 2017-01-04 12:30:32 | 2017-01-05 12:07:53\n\nproduct_info\n2 rows x 4 columns\n1. product_id | object | prd_1 | prd_2\n2. name | object | annual_subscription | monthly_subscription\n3. price | int64 | 1200 | 125\n4. billing_cycle | int64 | 12 | 1\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__gsagar12__dspp1/customer_cases.csv", "csv/kaggle__gsagar12__dspp1/customer_info.csv", "csv/kaggle__gsagar12__dspp1/customer_product.csv", "csv/kaggle__gsagar12__dspp1/product_info.csv"]}
{"id": "kaggle__gsagar12__dspp1__3", "question": "I have a database of Customer Subscription Data. As a market research analyst, I want to analyze customer subscription data to identify market trends.", "description": "\n\nCustomer Subscription Data\n\ncustomer_cases\n10016 rows x 6 columns\n1. Unnamed: 0 | int64 | 1 | 34 | 67 | 100 | 133\n2. case_id | object | CC101 | CC134 | CC167 | CC200 | CC233\n3. date_time | object | 2017-01-01 10:32:03 | 2017-01-02 12:18:54 | 2017-01-03 09:32:44 | 2017-01-03 12:45:09 | 2017-01-04 10:51:56\n4. customer_id | object | C2448 | C2481 | C2514 | C2547 | C2579\n5. channel | object | phone | phone | phone | phone | phone\n6. reason | object | signup | signup | signup | signup | signup\n\ncustomer_info\n10179 rows x 4 columns\n1. Unnamed: 0 | int64 | 1 | 51 | 101 | 151 | 201\n2. customer_id | object | C2448 | C2498 | C2548 | C2598 | C2648\n3. age | int64 | 76 | 59 | 59 | 60 | 33\n4. gender | object | female | female | female | male | male\n\ncustomer_product\n10179 rows x 4 columns\n1. Unnamed: 0 | int64 | 1 | 51 | 101 | 151 | 201\n2. customer_id | object | C2448 | C2498 | C2548 | C2598 | C2648\n3. product | object | prd_1 | prd_1 | prd_1 | prd_1 | prd_1\n4. signup_date_time | object | 2017-01-01 10:35:09 | 2017-01-02 13:40:10 | 2017-01-03 12:51:13 | 2017-01-04 12:30:32 | 2017-01-05 12:07:53\n\nproduct_info\n2 rows x 4 columns\n1. product_id | object | prd_1 | prd_2\n2. name | object | annual_subscription | monthly_subscription\n3. price | int64 | 1200 | 125\n4. billing_cycle | int64 | 12 | 1\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__gsagar12__dspp1/customer_cases.csv", "csv/kaggle__gsagar12__dspp1/customer_info.csv", "csv/kaggle__gsagar12__dspp1/customer_product.csv", "csv/kaggle__gsagar12__dspp1/product_info.csv"]}
{"id": "kaggle__epa__air-quality__0", "question": "I have a database of Air Quality Annual Summary. As an EPA administrator, I want to use this data to develop environmental policies.", "description": "\n\nAir Quality Annual Summary\n\nepa_air_quality_annual_summary\n5810 rows x 48 columns\n1. state_code | object | 20 | 15 | 04 | 28 | 41\n2. county_code | int64 | 57 | 1 | 7 | 47 | 35\n3. site_num | int64 | 1 | 5 | 8100 | 8 | 4\n4. parameter_code | int64 | 82134 | 88320 | 88203 | 88184 | 88166\n5. poc | int64 | 1 | 1 | 1 | 5 | 5\n6. latitude | float64 | 37.771964 | 19.4308 | 34.090866 | 30.390369 | 42.190296\n7. longitude | float64 | -100.01819 | -155.2578 | -110.942801 | -89.049778 | -121.731369\n8. datum | object | WGS84 | WGS84 | WGS84 | WGS84 | WGS84\n9. parameter_name | object | Molybdenum PM10 STP | OC PM2.5 LC TOR | Chloride PM2.5 LC | Sodium PM2.5 LC | Silver PM2.5 LC\n10. sample_duration | object | 24 HOUR | 24 HOUR | 24 HOUR | 24 HOUR | 24 HOUR\n11. metric_used | object | Observed Values | Observed Values | Observed Values | Observed Values | Observed Values\n12. method_name | object | HI-VOL-SA/GMW-1200 - EMISSION SPECTRA ICAP | IMPROVE - OC1+OC2+OC3+OC4+OP | IMPROVE Module B with Cyclone Inlet and Glycerin/Na2CO3-Nylon Filter 10.8 sq. cm. - Ion Chromatography | Met One SASS Teflon - Energy Dispersive XRF | Met One SASS Teflon - Energy Dispersive XRF\n13. year | int64 | 1997 | 2008 | 2009 | 2007 | 2011\n14. units_of_measure | object | Nanograms/cubic meter (25 C) | Micrograms/cubic meter (LC) | Micrograms/cubic meter (LC) | Micrograms/cubic meter (LC) | Micrograms/cubic meter (LC)\n15. event_type | object | No Events | No Events | No Events | No Events | No Events\n16. observation_count | int64 | 47 | 116 | 97 | 100 | 60\n17. observation_percent | int64 | 77 | 95 | 100 | 27 | 98\n18. completeness_indicator | object | N | Y | Y | N | Y\n19. valid_day_count | int64 | 47 | 116 | 55 | 100 | 60\n20. required_day_count | int64 | 61 | 122 | 61 | 365 | 61\n21. exceptional_data_count | int64 | 0 | 0 | 0 | 0 | 0\n22. null_data_count | int64 | 0 | 6 | 25 | 2 | 0\n23. certification_indicator | object | Certification not required | Certification not required | Certification not required | Certification not required | Certification not required\n24. num_obs_below_mdl | int64 | 0 | 0 | 0 | 0 | 0\n25. arithmetic_mean | float64 | 0.170213 | 0.1325 | 0.020211 | 0.12502 | 0.002272\n26. arithmetic_standard_dev | float64 | 0.731857 | 0.234676 | 0.03012 | 0.174574 | 0.003671\n27. first_max_value | float64 | 4.0 | 2.12 | 0.1467 | 0.745 | 0.0163\n28. first_max_datetime | object | 1997-01-28 00:00:00 | 2008-02-27 00:00:00 | 2009-04-28 00:00:00 | 2007-05-15 00:00:00 | 2011-04-09 00:00:00\n29. second_max_value | float64 | 3.0 | 0.83 | 0.1254 | 0.744 | 0.0139\n30. second_max_datetime | object | 1997-10-13 00:00:00 | 2008-07-26 00:00:00 | 2009-05-01 00:00:00 | 2007-10-18 00:00:00 | 2011-04-03 00:00:00\n31. third_max_value | float64 | 1.0 | 0.7 | 0.1014 | 0.622 | 0.011\n32. third_max_datetime | object | 1997-11-06 00:00:00 | 2008-03-01 00:00:00 | 2009-08-11 00:00:00 | 2007-01-12 00:00:00 | 2011-09-12 00:00:00\n33. fourth_max_value | float64 | 0.0 | 0.61 | 0.0938 | 0.605 | 0.0106\n34. fourth_max_datetime | object | 1997-01-04 00:00:00 | 2008-04-30 00:00:00 | 2009-04-10 00:00:00 | 2007-03-01 00:00:00 | 2011-04-15 00:00:00\n35. ninety_nine_percentile | float64 | 4.0 | 0.83 | 0.1467 | 0.745 | 0.0163\n36. ninety_eight_percentile | float64 | 4.0 | 0.7 | 0.1254 | 0.744 | 0.0139\n37. ninety_five_percentile | float64 | 1.0 | 0.43 | 0.0928 | 0.514 | 0.011\n38. ninety_percentile | float64 | 0.0 | 0.27 | 0.0617 | 0.417 | 0.00641\n39. seventy_five_percentile | float64 | 0.0 | 0.16 | 0.0205 | 0.164 | 0.003\n40. fifty_percentile | float64 | 0.0 | 0.09 | 0.0095 | 0.056 | 0.0\n41. ten_percentile | float64 | 0.0 | -0.01 | -0.0005 | 0.0 | 0.0\n42. local_site_name | object | DODGE CITY | Hawaii Volcanoes NP - Kilauea Visitors Center | Sierra Ancha | Gulfport Youth Court | Klamath Falls - Peterson School\n43. address | object | PUMP STATION 2100 1ST AVE | Hawaii Volcanoes National Park HI 96718 | Sierra Ancha | 47 Maple Street | PETERSON ELEM/4856 CLINTON ST\n44. state_name | object | Kansas | Hawaii | Arizona | Mississippi | Oregon\n45. county_name | object | Ford | Hawaii | Gila | Harrison | Klamath\n46. city_name | object | Dodge City | Hawaii Volcanoes National Park | Young | Gulfport | Altamont\n47. cbsa_name | object | Dodge City KS | Hilo HI | Payson AZ | Gulfport-Biloxi-Pascagoula MS | Klamath Falls OR\n48. date_of_last_change | object | 2012-08-11 | 2016-03-09 | 2016-03-09 | 2016-03-22 | 2016-03-09\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__epa__air-quality/epa_air_quality_annual_summary.csv"]}
{"id": "kaggle__epa__air-quality__1", "question": "I have a database of Air Quality Annual Summary. As an air quality consultant, I want to use this data to advise industry companies on pollution control measures.", "description": "\n\nAir Quality Annual Summary\n\nepa_air_quality_annual_summary\n5810 rows x 48 columns\n1. state_code | object | 20 | 15 | 04 | 28 | 41\n2. county_code | int64 | 57 | 1 | 7 | 47 | 35\n3. site_num | int64 | 1 | 5 | 8100 | 8 | 4\n4. parameter_code | int64 | 82134 | 88320 | 88203 | 88184 | 88166\n5. poc | int64 | 1 | 1 | 1 | 5 | 5\n6. latitude | float64 | 37.771964 | 19.4308 | 34.090866 | 30.390369 | 42.190296\n7. longitude | float64 | -100.01819 | -155.2578 | -110.942801 | -89.049778 | -121.731369\n8. datum | object | WGS84 | WGS84 | WGS84 | WGS84 | WGS84\n9. parameter_name | object | Molybdenum PM10 STP | OC PM2.5 LC TOR | Chloride PM2.5 LC | Sodium PM2.5 LC | Silver PM2.5 LC\n10. sample_duration | object | 24 HOUR | 24 HOUR | 24 HOUR | 24 HOUR | 24 HOUR\n11. metric_used | object | Observed Values | Observed Values | Observed Values | Observed Values | Observed Values\n12. method_name | object | HI-VOL-SA/GMW-1200 - EMISSION SPECTRA ICAP | IMPROVE - OC1+OC2+OC3+OC4+OP | IMPROVE Module B with Cyclone Inlet and Glycerin/Na2CO3-Nylon Filter 10.8 sq. cm. - Ion Chromatography | Met One SASS Teflon - Energy Dispersive XRF | Met One SASS Teflon - Energy Dispersive XRF\n13. year | int64 | 1997 | 2008 | 2009 | 2007 | 2011\n14. units_of_measure | object | Nanograms/cubic meter (25 C) | Micrograms/cubic meter (LC) | Micrograms/cubic meter (LC) | Micrograms/cubic meter (LC) | Micrograms/cubic meter (LC)\n15. event_type | object | No Events | No Events | No Events | No Events | No Events\n16. observation_count | int64 | 47 | 116 | 97 | 100 | 60\n17. observation_percent | int64 | 77 | 95 | 100 | 27 | 98\n18. completeness_indicator | object | N | Y | Y | N | Y\n19. valid_day_count | int64 | 47 | 116 | 55 | 100 | 60\n20. required_day_count | int64 | 61 | 122 | 61 | 365 | 61\n21. exceptional_data_count | int64 | 0 | 0 | 0 | 0 | 0\n22. null_data_count | int64 | 0 | 6 | 25 | 2 | 0\n23. certification_indicator | object | Certification not required | Certification not required | Certification not required | Certification not required | Certification not required\n24. num_obs_below_mdl | int64 | 0 | 0 | 0 | 0 | 0\n25. arithmetic_mean | float64 | 0.170213 | 0.1325 | 0.020211 | 0.12502 | 0.002272\n26. arithmetic_standard_dev | float64 | 0.731857 | 0.234676 | 0.03012 | 0.174574 | 0.003671\n27. first_max_value | float64 | 4.0 | 2.12 | 0.1467 | 0.745 | 0.0163\n28. first_max_datetime | object | 1997-01-28 00:00:00 | 2008-02-27 00:00:00 | 2009-04-28 00:00:00 | 2007-05-15 00:00:00 | 2011-04-09 00:00:00\n29. second_max_value | float64 | 3.0 | 0.83 | 0.1254 | 0.744 | 0.0139\n30. second_max_datetime | object | 1997-10-13 00:00:00 | 2008-07-26 00:00:00 | 2009-05-01 00:00:00 | 2007-10-18 00:00:00 | 2011-04-03 00:00:00\n31. third_max_value | float64 | 1.0 | 0.7 | 0.1014 | 0.622 | 0.011\n32. third_max_datetime | object | 1997-11-06 00:00:00 | 2008-03-01 00:00:00 | 2009-08-11 00:00:00 | 2007-01-12 00:00:00 | 2011-09-12 00:00:00\n33. fourth_max_value | float64 | 0.0 | 0.61 | 0.0938 | 0.605 | 0.0106\n34. fourth_max_datetime | object | 1997-01-04 00:00:00 | 2008-04-30 00:00:00 | 2009-04-10 00:00:00 | 2007-03-01 00:00:00 | 2011-04-15 00:00:00\n35. ninety_nine_percentile | float64 | 4.0 | 0.83 | 0.1467 | 0.745 | 0.0163\n36. ninety_eight_percentile | float64 | 4.0 | 0.7 | 0.1254 | 0.744 | 0.0139\n37. ninety_five_percentile | float64 | 1.0 | 0.43 | 0.0928 | 0.514 | 0.011\n38. ninety_percentile | float64 | 0.0 | 0.27 | 0.0617 | 0.417 | 0.00641\n39. seventy_five_percentile | float64 | 0.0 | 0.16 | 0.0205 | 0.164 | 0.003\n40. fifty_percentile | float64 | 0.0 | 0.09 | 0.0095 | 0.056 | 0.0\n41. ten_percentile | float64 | 0.0 | -0.01 | -0.0005 | 0.0 | 0.0\n42. local_site_name | object | DODGE CITY | Hawaii Volcanoes NP - Kilauea Visitors Center | Sierra Ancha | Gulfport Youth Court | Klamath Falls - Peterson School\n43. address | object | PUMP STATION 2100 1ST AVE | Hawaii Volcanoes National Park HI 96718 | Sierra Ancha | 47 Maple Street | PETERSON ELEM/4856 CLINTON ST\n44. state_name | object | Kansas | Hawaii | Arizona | Mississippi | Oregon\n45. county_name | object | Ford | Hawaii | Gila | Harrison | Klamath\n46. city_name | object | Dodge City | Hawaii Volcanoes National Park | Young | Gulfport | Altamont\n47. cbsa_name | object | Dodge City KS | Hilo HI | Payson AZ | Gulfport-Biloxi-Pascagoula MS | Klamath Falls OR\n48. date_of_last_change | object | 2012-08-11 | 2016-03-09 | 2016-03-09 | 2016-03-22 | 2016-03-09\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__epa__air-quality/epa_air_quality_annual_summary.csv"]}
{"id": "kaggle__joyshil0599__glassdoor-company-insightsscraped-data-collection__0", "question": "I have a database of USA Company Insights: Glassdoor Scraped Data 2023. As a human resources manager, I want to determine employee satisfaction levels in different companies.", "description": "\n\nUSA Company Insights: Glassdoor Scraped Data 2023\n\nglassdoor_comany\n8553 rows x 8 columns\n1. Company Name | object | Amazon | Deloitte | Target | McDonald's | Accenture\n2. Company rating | float64 | 3.8 | 4.1 | 3.6 | 3.5 | 4.0\n3. Company reviews | object | 168.8K | 97.2K | 75K | 117K | 145.1K\n4. Company salaries | object | 201.7K | 167.4K | 116.1K | 71.7K | 53.6K\n5. Company Jobs | object | 201.7K | 167.4K | 116.1K | 71.7K | 53.6K\n6. Location | object | 25 office locations in United States | 23 office locations in United States | 4 office locations in United States | 110 N Carpenter Street | United States\n7. Number of Employees | object | 10000+ Employees | 10000+ Employees | 10000+ Employees | 10000+ Employees | 10000+ Employees\n8. Industry Type | object | Internet & Web Services | Accounting & Tax | General Merchandise & Superstores | Restaurants & Cafes | Business Consulting\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__joyshil0599__glassdoor-company-insightsscraped-data-collection/glassdoor_comany.csv"]}
{"id": "kaggle__joyshil0599__glassdoor-company-insightsscraped-data-collection__1", "question": "I have a database of USA Company Insights: Glassdoor Scraped Data 2023. As a job seeker, I want to compare companies to make an informed decision about where to apply.", "description": "\n\nUSA Company Insights: Glassdoor Scraped Data 2023\n\nglassdoor_comany\n8553 rows x 8 columns\n1. Company Name | object | Amazon | Deloitte | Target | McDonald's | Accenture\n2. Company rating | float64 | 3.8 | 4.1 | 3.6 | 3.5 | 4.0\n3. Company reviews | object | 168.8K | 97.2K | 75K | 117K | 145.1K\n4. Company salaries | object | 201.7K | 167.4K | 116.1K | 71.7K | 53.6K\n5. Company Jobs | object | 201.7K | 167.4K | 116.1K | 71.7K | 53.6K\n6. Location | object | 25 office locations in United States | 23 office locations in United States | 4 office locations in United States | 110 N Carpenter Street | United States\n7. Number of Employees | object | 10000+ Employees | 10000+ Employees | 10000+ Employees | 10000+ Employees | 10000+ Employees\n8. Industry Type | object | Internet & Web Services | Accounting & Tax | General Merchandise & Superstores | Restaurants & Cafes | Business Consulting\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__joyshil0599__glassdoor-company-insightsscraped-data-collection/glassdoor_comany.csv"]}
{"id": "kaggle__joyshil0599__glassdoor-company-insightsscraped-data-collection__2", "question": "I have a database of USA Company Insights: Glassdoor Scraped Data 2023. As a business consultant, I want to advise clients on potential partnerships or acquisitions based on company insights.", "description": "\n\nUSA Company Insights: Glassdoor Scraped Data 2023\n\nglassdoor_comany\n8553 rows x 8 columns\n1. Company Name | object | Amazon | Deloitte | Target | McDonald's | Accenture\n2. Company rating | float64 | 3.8 | 4.1 | 3.6 | 3.5 | 4.0\n3. Company reviews | object | 168.8K | 97.2K | 75K | 117K | 145.1K\n4. Company salaries | object | 201.7K | 167.4K | 116.1K | 71.7K | 53.6K\n5. Company Jobs | object | 201.7K | 167.4K | 116.1K | 71.7K | 53.6K\n6. Location | object | 25 office locations in United States | 23 office locations in United States | 4 office locations in United States | 110 N Carpenter Street | United States\n7. Number of Employees | object | 10000+ Employees | 10000+ Employees | 10000+ Employees | 10000+ Employees | 10000+ Employees\n8. Industry Type | object | Internet & Web Services | Accounting & Tax | General Merchandise & Superstores | Restaurants & Cafes | Business Consulting\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__joyshil0599__glassdoor-company-insightsscraped-data-collection/glassdoor_comany.csv"]}
{"id": "kaggle__joyshil0599__glassdoor-company-insightsscraped-data-collection__3", "question": "I have a database of USA Company Insights: Glassdoor Scraped Data 2023. As a marketing executive, I want to identify companies with positive reputations to collaborate with for brand promotion.", "description": "\n\nUSA Company Insights: Glassdoor Scraped Data 2023\n\nglassdoor_comany\n8553 rows x 8 columns\n1. Company Name | object | Amazon | Deloitte | Target | McDonald's | Accenture\n2. Company rating | float64 | 3.8 | 4.1 | 3.6 | 3.5 | 4.0\n3. Company reviews | object | 168.8K | 97.2K | 75K | 117K | 145.1K\n4. Company salaries | object | 201.7K | 167.4K | 116.1K | 71.7K | 53.6K\n5. Company Jobs | object | 201.7K | 167.4K | 116.1K | 71.7K | 53.6K\n6. Location | object | 25 office locations in United States | 23 office locations in United States | 4 office locations in United States | 110 N Carpenter Street | United States\n7. Number of Employees | object | 10000+ Employees | 10000+ Employees | 10000+ Employees | 10000+ Employees | 10000+ Employees\n8. Industry Type | object | Internet & Web Services | Accounting & Tax | General Merchandise & Superstores | Restaurants & Cafes | Business Consulting\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__joyshil0599__glassdoor-company-insightsscraped-data-collection/glassdoor_comany.csv"]}
{"id": "kaggle__joyshil0599__glassdoor-company-insightsscraped-data-collection__4", "question": "I have a database of USA Company Insights: Glassdoor Scraped Data 2023. As a recruiter, I want to evaluate candidates' preferences for companies and industries to find the right fit.", "description": "\n\nUSA Company Insights: Glassdoor Scraped Data 2023\n\nglassdoor_comany\n8553 rows x 8 columns\n1. Company Name | object | Amazon | Deloitte | Target | McDonald's | Accenture\n2. Company rating | float64 | 3.8 | 4.1 | 3.6 | 3.5 | 4.0\n3. Company reviews | object | 168.8K | 97.2K | 75K | 117K | 145.1K\n4. Company salaries | object | 201.7K | 167.4K | 116.1K | 71.7K | 53.6K\n5. Company Jobs | object | 201.7K | 167.4K | 116.1K | 71.7K | 53.6K\n6. Location | object | 25 office locations in United States | 23 office locations in United States | 4 office locations in United States | 110 N Carpenter Street | United States\n7. Number of Employees | object | 10000+ Employees | 10000+ Employees | 10000+ Employees | 10000+ Employees | 10000+ Employees\n8. Industry Type | object | Internet & Web Services | Accounting & Tax | General Merchandise & Superstores | Restaurants & Cafes | Business Consulting\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__joyshil0599__glassdoor-company-insightsscraped-data-collection/glassdoor_comany.csv"]}
{"id": "kaggle__joyshil0599__glassdoor-company-insightsscraped-data-collection__5", "question": "I have a database of USA Company Insights: Glassdoor Scraped Data 2023. As a government official, I want to assess the overall health of companies in different industries for policy-making purposes.", "description": "\n\nUSA Company Insights: Glassdoor Scraped Data 2023\n\nglassdoor_comany\n8553 rows x 8 columns\n1. Company Name | object | Amazon | Deloitte | Target | McDonald's | Accenture\n2. Company rating | float64 | 3.8 | 4.1 | 3.6 | 3.5 | 4.0\n3. Company reviews | object | 168.8K | 97.2K | 75K | 117K | 145.1K\n4. Company salaries | object | 201.7K | 167.4K | 116.1K | 71.7K | 53.6K\n5. Company Jobs | object | 201.7K | 167.4K | 116.1K | 71.7K | 53.6K\n6. Location | object | 25 office locations in United States | 23 office locations in United States | 4 office locations in United States | 110 N Carpenter Street | United States\n7. Number of Employees | object | 10000+ Employees | 10000+ Employees | 10000+ Employees | 10000+ Employees | 10000+ Employees\n8. Industry Type | object | Internet & Web Services | Accounting & Tax | General Merchandise & Superstores | Restaurants & Cafes | Business Consulting\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__joyshil0599__glassdoor-company-insightsscraped-data-collection/glassdoor_comany.csv"]}
{"id": "kaggle__utkarshx27__world-religion-projections__0", "question": "I have a database of World Religion Projections 2010 to 2050. As a government official responsible for social services, I want to predict demographic changes in religious preferences and adjust resource allocation to match the needs of different religious communities.", "description": "\n\nWorld Religion Projections 2010 to 2050\n\nrounded_percentage\n1205 rows x 11 columns\n1. Year | int64 | 2010 | 2010 | 2010 | 2010 | 2010\n2. Region | object |  World | North America | Latin America-Caribbean | Europe | Middle East-North Africa\n3. Country | object |  All Countries |  All Countries |  All Countries |  All Countries |  All Countries\n4. Buddhists | float64 | 7.1 | 1.1 | 1.0 | 1.0 | 1.0\n5. Christians | float64 | 31.4 | 77.4 | 90.0 | 74.5 | 3.7\n6. Folk Religions | float64 | 5.9 | 1.0 | 1.7 | 1.0 | 1.0\n7. Hindus | float64 | 15.0 | 1.0 | 1.0 | 1.0 | 1.0\n8. Jews | float64 | 1.0 | 1.8 | 1.0 | 1.0 | 1.6\n9. Muslims | float64 | 23.2 | 1.0 | 1.0 | 5.9 | 93.0\n10. Other Religions | float64 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0\n11. Unaffiliated | float64 | 16.4 | 17.1 | 7.7 | 18.8 | 1.0\n\nrounded_population\n1205 rows x 12 columns\n1. Year | int64 | 2010 | 2010 | 2010 | 2010 | 2010\n2. Region | object |  World | North America | Latin America-Caribbean | Europe | Middle East-North Africa\n3. Country | object |  All Countries |  All Countries |  All Countries |  All Countries |  All Countries\n4. Christians | int64 | 2168330000 | 266630000 | 531280000 | 553280000 | 12710000\n5. Muslims | int64 | 1599700000 | 3480000 | 840000 | 43470000 | 317070000\n6. Unaffiliated | int64 | 1131150000 | 59040000 | 45390000 | 139890000 | 2100000\n7. Hindus | int64 | 1032210000 | 2250000 | 660000 | 1380000 | 1720000\n8. Buddhists | int64 | 487760000 | 3860000 | 410000 | 1350000 | 500000\n9. Folk Religions | int64 | 404690000 | 1020000 | 10040000 | 870000 | 1060000\n10. Other Religions | int64 | 58150000 | 2200000 | 990000 | 890000 | 230000\n11. Jews | int64 | 13860000 | 6040000 | 470000 | 1420000 | 5630000\n12. All Religions | int64 | 6895850000 | 344530000 | 590080000 | 742550000 | 341020000\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__utkarshx27__world-religion-projections/rounded_percentage.csv", "csv/kaggle__utkarshx27__world-religion-projections/rounded_population.csv"]}
{"id": "kaggle__utkarshx27__world-religion-projections__1", "question": "I have a database of World Religion Projections 2010 to 2050. As a business owner, I want to identify markets with growing or shrinking religious communities and tailor marketing campaigns and product offerings.", "description": "\n\nWorld Religion Projections 2010 to 2050\n\nrounded_percentage\n1205 rows x 11 columns\n1. Year | int64 | 2010 | 2010 | 2010 | 2010 | 2010\n2. Region | object |  World | North America | Latin America-Caribbean | Europe | Middle East-North Africa\n3. Country | object |  All Countries |  All Countries |  All Countries |  All Countries |  All Countries\n4. Buddhists | float64 | 7.1 | 1.1 | 1.0 | 1.0 | 1.0\n5. Christians | float64 | 31.4 | 77.4 | 90.0 | 74.5 | 3.7\n6. Folk Religions | float64 | 5.9 | 1.0 | 1.7 | 1.0 | 1.0\n7. Hindus | float64 | 15.0 | 1.0 | 1.0 | 1.0 | 1.0\n8. Jews | float64 | 1.0 | 1.8 | 1.0 | 1.0 | 1.6\n9. Muslims | float64 | 23.2 | 1.0 | 1.0 | 5.9 | 93.0\n10. Other Religions | float64 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0\n11. Unaffiliated | float64 | 16.4 | 17.1 | 7.7 | 18.8 | 1.0\n\nrounded_population\n1205 rows x 12 columns\n1. Year | int64 | 2010 | 2010 | 2010 | 2010 | 2010\n2. Region | object |  World | North America | Latin America-Caribbean | Europe | Middle East-North Africa\n3. Country | object |  All Countries |  All Countries |  All Countries |  All Countries |  All Countries\n4. Christians | int64 | 2168330000 | 266630000 | 531280000 | 553280000 | 12710000\n5. Muslims | int64 | 1599700000 | 3480000 | 840000 | 43470000 | 317070000\n6. Unaffiliated | int64 | 1131150000 | 59040000 | 45390000 | 139890000 | 2100000\n7. Hindus | int64 | 1032210000 | 2250000 | 660000 | 1380000 | 1720000\n8. Buddhists | int64 | 487760000 | 3860000 | 410000 | 1350000 | 500000\n9. Folk Religions | int64 | 404690000 | 1020000 | 10040000 | 870000 | 1060000\n10. Other Religions | int64 | 58150000 | 2200000 | 990000 | 890000 | 230000\n11. Jews | int64 | 13860000 | 6040000 | 470000 | 1420000 | 5630000\n12. All Religions | int64 | 6895850000 | 344530000 | 590080000 | 742550000 | 341020000\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__utkarshx27__world-religion-projections/rounded_percentage.csv", "csv/kaggle__utkarshx27__world-religion-projections/rounded_population.csv"]}
{"id": "kaggle__utkarshx27__world-religion-projections__2", "question": "I have a database of World Religion Projections 2010 to 2050. As a philanthropist, I want to support organizations or projects that promote interfaith understanding, tolerance, and cooperation.", "description": "\n\nWorld Religion Projections 2010 to 2050\n\nrounded_percentage\n1205 rows x 11 columns\n1. Year | int64 | 2010 | 2010 | 2010 | 2010 | 2010\n2. Region | object |  World | North America | Latin America-Caribbean | Europe | Middle East-North Africa\n3. Country | object |  All Countries |  All Countries |  All Countries |  All Countries |  All Countries\n4. Buddhists | float64 | 7.1 | 1.1 | 1.0 | 1.0 | 1.0\n5. Christians | float64 | 31.4 | 77.4 | 90.0 | 74.5 | 3.7\n6. Folk Religions | float64 | 5.9 | 1.0 | 1.7 | 1.0 | 1.0\n7. Hindus | float64 | 15.0 | 1.0 | 1.0 | 1.0 | 1.0\n8. Jews | float64 | 1.0 | 1.8 | 1.0 | 1.0 | 1.6\n9. Muslims | float64 | 23.2 | 1.0 | 1.0 | 5.9 | 93.0\n10. Other Religions | float64 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0\n11. Unaffiliated | float64 | 16.4 | 17.1 | 7.7 | 18.8 | 1.0\n\nrounded_population\n1205 rows x 12 columns\n1. Year | int64 | 2010 | 2010 | 2010 | 2010 | 2010\n2. Region | object |  World | North America | Latin America-Caribbean | Europe | Middle East-North Africa\n3. Country | object |  All Countries |  All Countries |  All Countries |  All Countries |  All Countries\n4. Christians | int64 | 2168330000 | 266630000 | 531280000 | 553280000 | 12710000\n5. Muslims | int64 | 1599700000 | 3480000 | 840000 | 43470000 | 317070000\n6. Unaffiliated | int64 | 1131150000 | 59040000 | 45390000 | 139890000 | 2100000\n7. Hindus | int64 | 1032210000 | 2250000 | 660000 | 1380000 | 1720000\n8. Buddhists | int64 | 487760000 | 3860000 | 410000 | 1350000 | 500000\n9. Folk Religions | int64 | 404690000 | 1020000 | 10040000 | 870000 | 1060000\n10. Other Religions | int64 | 58150000 | 2200000 | 990000 | 890000 | 230000\n11. Jews | int64 | 13860000 | 6040000 | 470000 | 1420000 | 5630000\n12. All Religions | int64 | 6895850000 | 344530000 | 590080000 | 742550000 | 341020000\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__utkarshx27__world-religion-projections/rounded_percentage.csv", "csv/kaggle__utkarshx27__world-religion-projections/rounded_population.csv"]}
{"id": "kaggle__uciml__pima-indians-diabetes-database__0", "question": "I have a database of Pima Indians Diabetes Database. As a medical device manufacturer, I want to develop tools to monitor and manage diabetes.", "description": "\n\nPima Indians Diabetes Database\n\ndiabetes\n768 rows x 9 columns\n1. Pregnancies | int64 | 6 | 1 | 8 | 1 | 0\n2. Glucose | int64 | 148 | 85 | 183 | 89 | 137\n3. BloodPressure | int64 | 72 | 66 | 64 | 66 | 40\n4. SkinThickness | int64 | 35 | 29 | 0 | 23 | 35\n5. Insulin | int64 | 0 | 0 | 0 | 94 | 168\n6. BMI | float64 | 33.6 | 26.6 | 23.3 | 28.1 | 43.1\n7. DiabetesPedigreeFunction | float64 | 0.627 | 0.351 | 0.672 | 0.167 | 2.288\n8. Age | int64 | 50 | 31 | 32 | 21 | 33\n9. Outcome | int64 | 1 | 0 | 1 | 0 | 1\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__uciml__pima-indians-diabetes-database/diabetes.csv"]}
{"id": "kaggle__uciml__pima-indians-diabetes-database__1", "question": "I have a database of Pima Indians Diabetes Database. As a nutritionist, I want to create meal plans for patients with diabetes.", "description": "\n\nPima Indians Diabetes Database\n\ndiabetes\n768 rows x 9 columns\n1. Pregnancies | int64 | 6 | 1 | 8 | 1 | 0\n2. Glucose | int64 | 148 | 85 | 183 | 89 | 137\n3. BloodPressure | int64 | 72 | 66 | 64 | 66 | 40\n4. SkinThickness | int64 | 35 | 29 | 0 | 23 | 35\n5. Insulin | int64 | 0 | 0 | 0 | 94 | 168\n6. BMI | float64 | 33.6 | 26.6 | 23.3 | 28.1 | 43.1\n7. DiabetesPedigreeFunction | float64 | 0.627 | 0.351 | 0.672 | 0.167 | 2.288\n8. Age | int64 | 50 | 31 | 32 | 21 | 33\n9. Outcome | int64 | 1 | 0 | 1 | 0 | 1\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__uciml__pima-indians-diabetes-database/diabetes.csv"]}
{"id": "kaggle__fhabibimoghaddam__customer-credit-card-data__1", "question": "I have a database of Customer Credit Card Data. As a data analyst, I want to identify correlations between customer demographics and credit card usage to improve marketing strategies.", "description": "\n\nCustomer Credit Card Data\n\nCustomer_Data\n8636 rows x 18 columns\n1. CUST_ID | object | C10001 | C10002 | C10003 | C10005 | C10006\n2. BALANCE | float64 | 40.900749 | 3202.467416 | 2495.148862 | 817.714335 | 1809.828751\n3. BALANCE_FREQUENCY | float64 | 0.818182 | 0.909091 | 1.0 | 1.0 | 1.0\n4. PURCHASES | float64 | 95.4 | 0.0 | 773.17 | 16.0 | 1333.28\n5. ONE_OFF_PURCHASES | float64 | 0.0 | 0.0 | 773.17 | 16.0 | 0.0\n6. INSTALLMENTS_PURCHASES | float64 | 95.4 | 0.0 | 0.0 | 0.0 | 1333.28\n7. CASH_ADVANCE | float64 | 0.0 | 6442.945483 | 0.0 | 0.0 | 0.0\n8. PURCHASES_FREQUENCY | float64 | 0.166667 | 0.0 | 1.0 | 0.083333 | 0.666667\n9. ONE_OFF_PURCHASES_FREQUENCY | float64 | 0.0 | 0.0 | 1.0 | 0.083333 | 0.0\n10. PURCHASES_INSTALLMENTS_FREQUENCY | float64 | 0.083333 | 0.0 | 0.0 | 0.0 | 0.583333\n11. CASH_ADVANCE_FREQUENCY | float64 | 0.0 | 0.25 | 0.0 | 0.0 | 0.0\n12. CASH_ADVANCE_TRX | int64 | 0 | 4 | 0 | 0 | 0\n13. PURCHASES_TRX | int64 | 2 | 0 | 12 | 1 | 8\n14. CREDIT_LIMIT | float64 | 1000.0 | 7000.0 | 7500.0 | 1200.0 | 1800.0\n15. PAYMENTS | float64 | 201.802084 | 4103.032597 | 622.066742 | 678.334763 | 1400.05777\n16. MINIMUM_PAYMENTS | float64 | 139.509787 | 1072.340217 | 627.284787 | 244.791237 | 2407.246035\n17. PRC_FULL_PAYMENT | float64 | 0.0 | 0.222222 | 0.0 | 0.0 | 0.0\n18. TENURE | int64 | 12 | 12 | 12 | 12 | 12\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__fhabibimoghaddam__customer-credit-card-data/Customer_Data.csv"]}
{"id": "kaggle__pranav941__evolution-of-smartphones__0", "question": "I have a database of üì±Smartphones Historical Data. As a smartphone manufacturer, I want to analyze trends in smartphone features to inform product development and marketing strategies.", "description": "\n\nüì±Smartphones Historical Data\n\nSmartphone_Evolution\n2467 rows x 12 columns\n1. Brand | object | ARCHOS | ARCHOS | ARCHOS | ARCHOS | ARCHOS\n2. Model | object | 40 Cesium | 40b Titanium | 45b Helium 4G | 45c Platinum | 50 Cesium\n3. OS | object | Windows Phone 8.1 | Android 4.2.2 | Android 4.4.4 | Android 4.4.2 | Windows 10 Mobile\n4. Battery | float64 | 1950.0 | 1400.0 | 1850.0 | 1700.0 | 2100.0\n5. Processor | object | Qualcomm Snapdragon 200 | MediaTek | Qualcomm Snapdragon 410 | MediaTek | Qualcomm Snapdragon 210\n6. Memory | float64 | 0.5 | 0.5 | 0.5 | 0.5 | 1.0\n7. Primary_Storage | float64 | 4.0 | 4.0 | 4.0 | 4.0 | 8.0\n8. External_Storage | object |  microSDXC |  microSD |  microSDXC |  microSDHC |  microSDHC\n9. Display_Size | float64 | 4.0 | 4.0 | 4.5 | 4.5 | 5.0\n10. Display_Resolution | object | 800 x 480  | 800 x 480  | 854 x 480  | 854 x 480  | 1280 x 720 \n11. Primary_Camera | float64 | 5.0 | 5.0 | 5.0 | 5.0 | 8.0\n12. Front_Camera | object | 0.3  | 0.3  | 0.3  | 2  | 2 \n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__pranav941__evolution-of-smartphones/Smartphone_Evolution.csv"]}
{"id": "kaggle__pranav941__evolution-of-smartphones__1", "question": "I have a database of üì±Smartphones Historical Data. As a mobile network provider, I want to assess compatibility with different smartphone models to optimize network performance and customer satisfaction.", "description": "\n\nüì±Smartphones Historical Data\n\nSmartphone_Evolution\n2467 rows x 12 columns\n1. Brand | object | ARCHOS | ARCHOS | ARCHOS | ARCHOS | ARCHOS\n2. Model | object | 40 Cesium | 40b Titanium | 45b Helium 4G | 45c Platinum | 50 Cesium\n3. OS | object | Windows Phone 8.1 | Android 4.2.2 | Android 4.4.4 | Android 4.4.2 | Windows 10 Mobile\n4. Battery | float64 | 1950.0 | 1400.0 | 1850.0 | 1700.0 | 2100.0\n5. Processor | object | Qualcomm Snapdragon 200 | MediaTek | Qualcomm Snapdragon 410 | MediaTek | Qualcomm Snapdragon 210\n6. Memory | float64 | 0.5 | 0.5 | 0.5 | 0.5 | 1.0\n7. Primary_Storage | float64 | 4.0 | 4.0 | 4.0 | 4.0 | 8.0\n8. External_Storage | object |  microSDXC |  microSD |  microSDXC |  microSDHC |  microSDHC\n9. Display_Size | float64 | 4.0 | 4.0 | 4.5 | 4.5 | 5.0\n10. Display_Resolution | object | 800 x 480  | 800 x 480  | 854 x 480  | 854 x 480  | 1280 x 720 \n11. Primary_Camera | float64 | 5.0 | 5.0 | 5.0 | 5.0 | 8.0\n12. Front_Camera | object | 0.3  | 0.3  | 0.3  | 2  | 2 \n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__pranav941__evolution-of-smartphones/Smartphone_Evolution.csv"]}
{"id": "kaggle__pranav941__evolution-of-smartphones__2", "question": "I have a database of üì±Smartphones Historical Data. As a software developer, I want to identify the most popular smartphone operating systems to prioritize platform support and feature development.", "description": "\n\nüì±Smartphones Historical Data\n\nSmartphone_Evolution\n2467 rows x 12 columns\n1. Brand | object | ARCHOS | ARCHOS | ARCHOS | ARCHOS | ARCHOS\n2. Model | object | 40 Cesium | 40b Titanium | 45b Helium 4G | 45c Platinum | 50 Cesium\n3. OS | object | Windows Phone 8.1 | Android 4.2.2 | Android 4.4.4 | Android 4.4.2 | Windows 10 Mobile\n4. Battery | float64 | 1950.0 | 1400.0 | 1850.0 | 1700.0 | 2100.0\n5. Processor | object | Qualcomm Snapdragon 200 | MediaTek | Qualcomm Snapdragon 410 | MediaTek | Qualcomm Snapdragon 210\n6. Memory | float64 | 0.5 | 0.5 | 0.5 | 0.5 | 1.0\n7. Primary_Storage | float64 | 4.0 | 4.0 | 4.0 | 4.0 | 8.0\n8. External_Storage | object |  microSDXC |  microSD |  microSDXC |  microSDHC |  microSDHC\n9. Display_Size | float64 | 4.0 | 4.0 | 4.5 | 4.5 | 5.0\n10. Display_Resolution | object | 800 x 480  | 800 x 480  | 854 x 480  | 854 x 480  | 1280 x 720 \n11. Primary_Camera | float64 | 5.0 | 5.0 | 5.0 | 5.0 | 8.0\n12. Front_Camera | object | 0.3  | 0.3  | 0.3  | 2  | 2 \n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__pranav941__evolution-of-smartphones/Smartphone_Evolution.csv"]}
{"id": "kaggle__pranav941__evolution-of-smartphones__3", "question": "I have a database of üì±Smartphones Historical Data. As a retail store owner, I want to determine the most popular smartphone brands and models to inform inventory management and marketing strategies.", "description": "\n\nüì±Smartphones Historical Data\n\nSmartphone_Evolution\n2467 rows x 12 columns\n1. Brand | object | ARCHOS | ARCHOS | ARCHOS | ARCHOS | ARCHOS\n2. Model | object | 40 Cesium | 40b Titanium | 45b Helium 4G | 45c Platinum | 50 Cesium\n3. OS | object | Windows Phone 8.1 | Android 4.2.2 | Android 4.4.4 | Android 4.4.2 | Windows 10 Mobile\n4. Battery | float64 | 1950.0 | 1400.0 | 1850.0 | 1700.0 | 2100.0\n5. Processor | object | Qualcomm Snapdragon 200 | MediaTek | Qualcomm Snapdragon 410 | MediaTek | Qualcomm Snapdragon 210\n6. Memory | float64 | 0.5 | 0.5 | 0.5 | 0.5 | 1.0\n7. Primary_Storage | float64 | 4.0 | 4.0 | 4.0 | 4.0 | 8.0\n8. External_Storage | object |  microSDXC |  microSD |  microSDXC |  microSDHC |  microSDHC\n9. Display_Size | float64 | 4.0 | 4.0 | 4.5 | 4.5 | 5.0\n10. Display_Resolution | object | 800 x 480  | 800 x 480  | 854 x 480  | 854 x 480  | 1280 x 720 \n11. Primary_Camera | float64 | 5.0 | 5.0 | 5.0 | 5.0 | 8.0\n12. Front_Camera | object | 0.3  | 0.3  | 0.3  | 2  | 2 \n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__pranav941__evolution-of-smartphones/Smartphone_Evolution.csv"]}
{"id": "kaggle__themrityunjaypathak__most-subscribed-1000-youtube-channels__0", "question": "I have a database of Most Subscribed 1000 Youtube Channelsüî¥. As a marketing manager, I want to decide on the channels for potential collaborations and sponsorships.", "description": "\n\nMost Subscribed 1000 Youtube Channelsüî¥\n\ntopSubscribed\n1000 rows x 7 columns\n1. Rank | int64 | 1 | 2 | 3 | 4 | 5\n2. Youtube Channel | object | T-Series | YouTube Movies | Cocomelon - Nursery Rhymes | SET India | MrBeast\n3. Subscribers | object | 234,000,000 | 161,000,000 | 152,000,000 | 150,000,000 | 128,000,000\n4. Video Views | object | 212,900,271,553 | 0 | 149,084,178,448 | 137,828,094,104 | 21,549,128,785\n5. Video Count | object | 18,515 | 0 | 846 | 103,200 | 733\n6. Category | object | Music | Film & Animation | Education | Shows | Entertainment\n7. Started | int64 | 2006 | 2015 | 2006 | 2006 | 2012\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__themrityunjaypathak__most-subscribed-1000-youtube-channels/topSubscribed.csv"]}
{"id": "kaggle__themrityunjaypathak__most-subscribed-1000-youtube-channels__1", "question": "I have a database of Most Subscribed 1000 Youtube Channelsüî¥. As a content creator, I want to analyze the trends and strategies used by the top subscribed channels to improve my own content.", "description": "\n\nMost Subscribed 1000 Youtube Channelsüî¥\n\ntopSubscribed\n1000 rows x 7 columns\n1. Rank | int64 | 1 | 2 | 3 | 4 | 5\n2. Youtube Channel | object | T-Series | YouTube Movies | Cocomelon - Nursery Rhymes | SET India | MrBeast\n3. Subscribers | object | 234,000,000 | 161,000,000 | 152,000,000 | 150,000,000 | 128,000,000\n4. Video Views | object | 212,900,271,553 | 0 | 149,084,178,448 | 137,828,094,104 | 21,549,128,785\n5. Video Count | object | 18,515 | 0 | 846 | 103,200 | 733\n6. Category | object | Music | Film & Animation | Education | Shows | Entertainment\n7. Started | int64 | 2006 | 2015 | 2006 | 2006 | 2012\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__themrityunjaypathak__most-subscribed-1000-youtube-channels/topSubscribed.csv"]}
{"id": "kaggle__themrityunjaypathak__most-subscribed-1000-youtube-channels__2", "question": "I have a database of Most Subscribed 1000 Youtube Channelsüî¥. As an advertising executive, I want to select the channels for targeted ad placements.", "description": "\n\nMost Subscribed 1000 Youtube Channelsüî¥\n\ntopSubscribed\n1000 rows x 7 columns\n1. Rank | int64 | 1 | 2 | 3 | 4 | 5\n2. Youtube Channel | object | T-Series | YouTube Movies | Cocomelon - Nursery Rhymes | SET India | MrBeast\n3. Subscribers | object | 234,000,000 | 161,000,000 | 152,000,000 | 150,000,000 | 128,000,000\n4. Video Views | object | 212,900,271,553 | 0 | 149,084,178,448 | 137,828,094,104 | 21,549,128,785\n5. Video Count | object | 18,515 | 0 | 846 | 103,200 | 733\n6. Category | object | Music | Film & Animation | Education | Shows | Entertainment\n7. Started | int64 | 2006 | 2015 | 2006 | 2006 | 2012\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__themrityunjaypathak__most-subscribed-1000-youtube-channels/topSubscribed.csv"]}
{"id": "kaggle__themrityunjaypathak__most-subscribed-1000-youtube-channels__3", "question": "I have a database of Most Subscribed 1000 Youtube Channelsüî¥. As a platform developer, I want to analyze user behavior and preferences to optimize the user experience.", "description": "\n\nMost Subscribed 1000 Youtube Channelsüî¥\n\ntopSubscribed\n1000 rows x 7 columns\n1. Rank | int64 | 1 | 2 | 3 | 4 | 5\n2. Youtube Channel | object | T-Series | YouTube Movies | Cocomelon - Nursery Rhymes | SET India | MrBeast\n3. Subscribers | object | 234,000,000 | 161,000,000 | 152,000,000 | 150,000,000 | 128,000,000\n4. Video Views | object | 212,900,271,553 | 0 | 149,084,178,448 | 137,828,094,104 | 21,549,128,785\n5. Video Count | object | 18,515 | 0 | 846 | 103,200 | 733\n6. Category | object | Music | Film & Animation | Education | Shows | Entertainment\n7. Started | int64 | 2006 | 2015 | 2006 | 2006 | 2012\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__themrityunjaypathak__most-subscribed-1000-youtube-channels/topSubscribed.csv"]}
{"id": "kaggle__themrityunjaypathak__most-subscribed-1000-youtube-channels__4", "question": "I have a database of Most Subscribed 1000 Youtube Channelsüî¥. As a brand manager, I want to identify channels that align with my brand values for potential partnerships.", "description": "\n\nMost Subscribed 1000 Youtube Channelsüî¥\n\ntopSubscribed\n1000 rows x 7 columns\n1. Rank | int64 | 1 | 2 | 3 | 4 | 5\n2. Youtube Channel | object | T-Series | YouTube Movies | Cocomelon - Nursery Rhymes | SET India | MrBeast\n3. Subscribers | object | 234,000,000 | 161,000,000 | 152,000,000 | 150,000,000 | 128,000,000\n4. Video Views | object | 212,900,271,553 | 0 | 149,084,178,448 | 137,828,094,104 | 21,549,128,785\n5. Video Count | object | 18,515 | 0 | 846 | 103,200 | 733\n6. Category | object | Music | Film & Animation | Education | Shows | Entertainment\n7. Started | int64 | 2006 | 2015 | 2006 | 2006 | 2012\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__themrityunjaypathak__most-subscribed-1000-youtube-channels/topSubscribed.csv"]}
{"id": "kaggle__themrityunjaypathak__most-subscribed-1000-youtube-channels__5", "question": "I have a database of Most Subscribed 1000 Youtube Channelsüî¥. As a data analyst, I want to identify patterns and insights from the top subscribed channels to inform business strategies.", "description": "\n\nMost Subscribed 1000 Youtube Channelsüî¥\n\ntopSubscribed\n1000 rows x 7 columns\n1. Rank | int64 | 1 | 2 | 3 | 4 | 5\n2. Youtube Channel | object | T-Series | YouTube Movies | Cocomelon - Nursery Rhymes | SET India | MrBeast\n3. Subscribers | object | 234,000,000 | 161,000,000 | 152,000,000 | 150,000,000 | 128,000,000\n4. Video Views | object | 212,900,271,553 | 0 | 149,084,178,448 | 137,828,094,104 | 21,549,128,785\n5. Video Count | object | 18,515 | 0 | 846 | 103,200 | 733\n6. Category | object | Music | Film & Animation | Education | Shows | Entertainment\n7. Started | int64 | 2006 | 2015 | 2006 | 2006 | 2012\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__themrityunjaypathak__most-subscribed-1000-youtube-channels/topSubscribed.csv"]}
{"id": "kaggle__themrityunjaypathak__most-subscribed-1000-youtube-channels__6", "question": "I have a database of Most Subscribed 1000 Youtube Channelsüî¥. As a content aggregator, I want to curate and recommend popular channels for my platform or streaming service.", "description": "\n\nMost Subscribed 1000 Youtube Channelsüî¥\n\ntopSubscribed\n1000 rows x 7 columns\n1. Rank | int64 | 1 | 2 | 3 | 4 | 5\n2. Youtube Channel | object | T-Series | YouTube Movies | Cocomelon - Nursery Rhymes | SET India | MrBeast\n3. Subscribers | object | 234,000,000 | 161,000,000 | 152,000,000 | 150,000,000 | 128,000,000\n4. Video Views | object | 212,900,271,553 | 0 | 149,084,178,448 | 137,828,094,104 | 21,549,128,785\n5. Video Count | object | 18,515 | 0 | 846 | 103,200 | 733\n6. Category | object | Music | Film & Animation | Education | Shows | Entertainment\n7. Started | int64 | 2006 | 2015 | 2006 | 2006 | 2012\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__themrityunjaypathak__most-subscribed-1000-youtube-channels/topSubscribed.csv"]}
{"id": "kaggle__davinwijaya__customer-retention__0", "question": "I have a database of Marketing Promotion Campaign Uplift Modelling. As the sales director, I want to allocate resources and budget to the promotion campaigns that yield the highest conversion rates.", "description": "\n\nMarketing Promotion Campaign Uplift Modelling\n\ndata\n10667 rows x 9 columns\n1. recency | int64 | 10 | 9 | 5 | 11 | 4\n2. history | float64 | 142.44 | 280.2 | 642.9 | 219.04 | 78.24\n3. used_discount | int64 | 1 | 1 | 0 | 1 | 1\n4. used_bogo | int64 | 0 | 0 | 1 | 1 | 0\n5. zip_code | object | Surburban | Surburban | Surburban | Surburban | Surburban\n6. is_referral | int64 | 0 | 1 | 1 | 0 | 0\n7. channel | object | Phone | Phone | Multichannel | Phone | Web\n8. offer | object | Buy One Get One | Buy One Get One | Buy One Get One | Discount | No Offer\n9. conversion | int64 | 0 | 0 | 0 | 0 | 0\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__davinwijaya__customer-retention/data.csv"]}
{"id": "kaggle__davinwijaya__customer-retention__1", "question": "I have a database of Marketing Promotion Campaign Uplift Modelling. As the product manager, I want to analyze the impact of different promotional offers on customer conversions and optimize our future offer strategies.", "description": "\n\nMarketing Promotion Campaign Uplift Modelling\n\ndata\n10667 rows x 9 columns\n1. recency | int64 | 10 | 9 | 5 | 11 | 4\n2. history | float64 | 142.44 | 280.2 | 642.9 | 219.04 | 78.24\n3. used_discount | int64 | 1 | 1 | 0 | 1 | 1\n4. used_bogo | int64 | 0 | 0 | 1 | 1 | 0\n5. zip_code | object | Surburban | Surburban | Surburban | Surburban | Surburban\n6. is_referral | int64 | 0 | 1 | 1 | 0 | 0\n7. channel | object | Phone | Phone | Multichannel | Phone | Web\n8. offer | object | Buy One Get One | Buy One Get One | Buy One Get One | Discount | No Offer\n9. conversion | int64 | 0 | 0 | 0 | 0 | 0\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__davinwijaya__customer-retention/data.csv"]}
{"id": "kaggle__davinwijaya__customer-retention__2", "question": "I have a database of Marketing Promotion Campaign Uplift Modelling. As the customer service manager, I want to identify customers who are more likely to convert through promotions and tailor our service offerings to meet their needs.", "description": "\n\nMarketing Promotion Campaign Uplift Modelling\n\ndata\n10667 rows x 9 columns\n1. recency | int64 | 10 | 9 | 5 | 11 | 4\n2. history | float64 | 142.44 | 280.2 | 642.9 | 219.04 | 78.24\n3. used_discount | int64 | 1 | 1 | 0 | 1 | 1\n4. used_bogo | int64 | 0 | 0 | 1 | 1 | 0\n5. zip_code | object | Surburban | Surburban | Surburban | Surburban | Surburban\n6. is_referral | int64 | 0 | 1 | 1 | 0 | 0\n7. channel | object | Phone | Phone | Multichannel | Phone | Web\n8. offer | object | Buy One Get One | Buy One Get One | Buy One Get One | Discount | No Offer\n9. conversion | int64 | 0 | 0 | 0 | 0 | 0\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__davinwijaya__customer-retention/data.csv"]}
{"id": "kaggle__utkarshx27__mpox-monkeypox-data__0", "question": "I have a database of Mpox (Monkeypox) Data. As a public health official, I want to identify and track the spread of monkeypox in different countries.", "description": "\n\nMpox (Monkeypox) Data\n\nowid-monkeypox-data\n11222 rows x 15 columns\n1. location | object | Africa | Africa | Africa | Africa | Africa\n2. iso_code | object | OWID_AFR | OWID_AFR | OWID_AFR | OWID_AFR | OWID_AFR\n3. date | object | 2022-05-01 | 2022-05-04 | 2022-05-07 | 2022-05-10 | 2022-05-13\n4. total_cases | float64 | 27.0 | 27.0 | 27.0 | 27.0 | 31.0\n5. total_deaths | float64 | 2.0 | 2.0 | 2.0 | 2.0 | 2.0\n6. new_cases | float64 | 0.0 | 0.0 | 0.0 | 0.0 | 4.0\n7. new_deaths | float64 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0\n8. new_cases_smoothed | float64 | 0.29 | 0.29 | 0.0 | 0.0 | 0.57\n9. new_deaths_smoothed | float64 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0\n10. new_cases_per_million | float64 | 0.0 | 0.0 | 0.0 | 0.0 | 0.003\n11. total_cases_per_million | float64 | 0.019 | 0.019 | 0.019 | 0.019 | 0.022\n12. new_cases_smoothed_per_million | float64 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0\n13. new_deaths_per_million | float64 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0\n14. total_deaths_per_million | float64 | 0.0014 | 0.0014 | 0.0014 | 0.0014 | 0.0014\n15. new_deaths_smoothed_per_million | float64 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__utkarshx27__mpox-monkeypox-data/owid-monkeypox-data.csv"]}
{"id": "kaggle__kalilurrahman__nasdaq100-stock-price-data__0", "question": "I have a database of NASDAQ-100 Stock Price Data. As an individual investor, I want to decide on buying or selling my shares in NASDAQ-100 companies.", "description": "\n\nNASDAQ-100 Stock Price Data\n\nNASDAQ_100_Data_From_2010\n10063 rows x 8 columns\n1. Date | object | 2010-01-04 | 2010-02-11 | 2010-03-23 | 2010-04-30 | 2010-06-09\n2. Open | float64 | 7.622499942779541 | 6.960000038146973 | 8.058570861816406 | 9.618213653564451 | 8.981071472167969\n3. High | float64 | 7.660714149475098 | 7.1339287757873535 | 8.170714378356934 | 9.663213729858398 | 8.996429443359375\n4. Low | float64 | 7.585000038146973 | 6.930714130401611 | 8.003570556640625 | 9.321429252624512 | 8.660357475280762\n5. Close | float64 | 7.643214225769043 | 7.0953569412231445 | 8.15571403503418 | 9.3246431350708 | 8.685713768005371\n6. Adj Close | float64 | 6.562590599060059 | 6.092190742492676 | 7.002628803253174 | 8.0062894821167 | 7.457696437835693\n7. Volume | int64 | 493729600 | 550345600 | 602431200 | 542463600 | 854630000\n8. Name | object | AAPL | AAPL | AAPL | AAPL | AAPL\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__kalilurrahman__nasdaq100-stock-price-data/NASDAQ_100_Data_From_2010.csv"]}
{"id": "kaggle__kalilurrahman__nasdaq100-stock-price-data__1", "question": "I have a database of NASDAQ-100 Stock Price Data. As a stockbroker, I want to provide insights to my clients on the performance of NASDAQ-100 companies.", "description": "\n\nNASDAQ-100 Stock Price Data\n\nNASDAQ_100_Data_From_2010\n10063 rows x 8 columns\n1. Date | object | 2010-01-04 | 2010-02-11 | 2010-03-23 | 2010-04-30 | 2010-06-09\n2. Open | float64 | 7.622499942779541 | 6.960000038146973 | 8.058570861816406 | 9.618213653564451 | 8.981071472167969\n3. High | float64 | 7.660714149475098 | 7.1339287757873535 | 8.170714378356934 | 9.663213729858398 | 8.996429443359375\n4. Low | float64 | 7.585000038146973 | 6.930714130401611 | 8.003570556640625 | 9.321429252624512 | 8.660357475280762\n5. Close | float64 | 7.643214225769043 | 7.0953569412231445 | 8.15571403503418 | 9.3246431350708 | 8.685713768005371\n6. Adj Close | float64 | 6.562590599060059 | 6.092190742492676 | 7.002628803253174 | 8.0062894821167 | 7.457696437835693\n7. Volume | int64 | 493729600 | 550345600 | 602431200 | 542463600 | 854630000\n8. Name | object | AAPL | AAPL | AAPL | AAPL | AAPL\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__kalilurrahman__nasdaq100-stock-price-data/NASDAQ_100_Data_From_2010.csv"]}
{"id": "kaggle__kalilurrahman__nasdaq100-stock-price-data__2", "question": "I have a database of NASDAQ-100 Stock Price Data. As a research analyst, I want to provide market insights and forecasts to investors.", "description": "\n\nNASDAQ-100 Stock Price Data\n\nNASDAQ_100_Data_From_2010\n10063 rows x 8 columns\n1. Date | object | 2010-01-04 | 2010-02-11 | 2010-03-23 | 2010-04-30 | 2010-06-09\n2. Open | float64 | 7.622499942779541 | 6.960000038146973 | 8.058570861816406 | 9.618213653564451 | 8.981071472167969\n3. High | float64 | 7.660714149475098 | 7.1339287757873535 | 8.170714378356934 | 9.663213729858398 | 8.996429443359375\n4. Low | float64 | 7.585000038146973 | 6.930714130401611 | 8.003570556640625 | 9.321429252624512 | 8.660357475280762\n5. Close | float64 | 7.643214225769043 | 7.0953569412231445 | 8.15571403503418 | 9.3246431350708 | 8.685713768005371\n6. Adj Close | float64 | 6.562590599060059 | 6.092190742492676 | 7.002628803253174 | 8.0062894821167 | 7.457696437835693\n7. Volume | int64 | 493729600 | 550345600 | 602431200 | 542463600 | 854630000\n8. Name | object | AAPL | AAPL | AAPL | AAPL | AAPL\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__kalilurrahman__nasdaq100-stock-price-data/NASDAQ_100_Data_From_2010.csv"]}
{"id": "kaggle__kalilurrahman__nasdaq100-stock-price-data__3", "question": "I have a database of NASDAQ-100 Stock Price Data. As a retirement planner, I want to monitor the NASDAQ-100 performance for long-term investment strategies.", "description": "\n\nNASDAQ-100 Stock Price Data\n\nNASDAQ_100_Data_From_2010\n10063 rows x 8 columns\n1. Date | object | 2010-01-04 | 2010-02-11 | 2010-03-23 | 2010-04-30 | 2010-06-09\n2. Open | float64 | 7.622499942779541 | 6.960000038146973 | 8.058570861816406 | 9.618213653564451 | 8.981071472167969\n3. High | float64 | 7.660714149475098 | 7.1339287757873535 | 8.170714378356934 | 9.663213729858398 | 8.996429443359375\n4. Low | float64 | 7.585000038146973 | 6.930714130401611 | 8.003570556640625 | 9.321429252624512 | 8.660357475280762\n5. Close | float64 | 7.643214225769043 | 7.0953569412231445 | 8.15571403503418 | 9.3246431350708 | 8.685713768005371\n6. Adj Close | float64 | 6.562590599060059 | 6.092190742492676 | 7.002628803253174 | 8.0062894821167 | 7.457696437835693\n7. Volume | int64 | 493729600 | 550345600 | 602431200 | 542463600 | 854630000\n8. Name | object | AAPL | AAPL | AAPL | AAPL | AAPL\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__kalilurrahman__nasdaq100-stock-price-data/NASDAQ_100_Data_From_2010.csv"]}
{"id": "kaggle__kalilurrahman__nasdaq100-stock-price-data__4", "question": "I have a database of NASDAQ-100 Stock Price Data. As a mutual fund manager, I want to make adjustments to my fund‚Äôs investments based on the NASDAQ-100 performance.", "description": "\n\nNASDAQ-100 Stock Price Data\n\nNASDAQ_100_Data_From_2010\n10063 rows x 8 columns\n1. Date | object | 2010-01-04 | 2010-02-11 | 2010-03-23 | 2010-04-30 | 2010-06-09\n2. Open | float64 | 7.622499942779541 | 6.960000038146973 | 8.058570861816406 | 9.618213653564451 | 8.981071472167969\n3. High | float64 | 7.660714149475098 | 7.1339287757873535 | 8.170714378356934 | 9.663213729858398 | 8.996429443359375\n4. Low | float64 | 7.585000038146973 | 6.930714130401611 | 8.003570556640625 | 9.321429252624512 | 8.660357475280762\n5. Close | float64 | 7.643214225769043 | 7.0953569412231445 | 8.15571403503418 | 9.3246431350708 | 8.685713768005371\n6. Adj Close | float64 | 6.562590599060059 | 6.092190742492676 | 7.002628803253174 | 8.0062894821167 | 7.457696437835693\n7. Volume | int64 | 493729600 | 550345600 | 602431200 | 542463600 | 854630000\n8. Name | object | AAPL | AAPL | AAPL | AAPL | AAPL\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__kalilurrahman__nasdaq100-stock-price-data/NASDAQ_100_Data_From_2010.csv"]}
{"id": "kaggle__kalilurrahman__nasdaq100-stock-price-data__5", "question": "I have a database of NASDAQ-100 Stock Price Data. As a financial advisor, I want to use the data to help my clients make informed investment decisions.", "description": "\n\nNASDAQ-100 Stock Price Data\n\nNASDAQ_100_Data_From_2010\n10063 rows x 8 columns\n1. Date | object | 2010-01-04 | 2010-02-11 | 2010-03-23 | 2010-04-30 | 2010-06-09\n2. Open | float64 | 7.622499942779541 | 6.960000038146973 | 8.058570861816406 | 9.618213653564451 | 8.981071472167969\n3. High | float64 | 7.660714149475098 | 7.1339287757873535 | 8.170714378356934 | 9.663213729858398 | 8.996429443359375\n4. Low | float64 | 7.585000038146973 | 6.930714130401611 | 8.003570556640625 | 9.321429252624512 | 8.660357475280762\n5. Close | float64 | 7.643214225769043 | 7.0953569412231445 | 8.15571403503418 | 9.3246431350708 | 8.685713768005371\n6. Adj Close | float64 | 6.562590599060059 | 6.092190742492676 | 7.002628803253174 | 8.0062894821167 | 7.457696437835693\n7. Volume | int64 | 493729600 | 550345600 | 602431200 | 542463600 | 854630000\n8. Name | object | AAPL | AAPL | AAPL | AAPL | AAPL\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__kalilurrahman__nasdaq100-stock-price-data/NASDAQ_100_Data_From_2010.csv"]}
{"id": "kaggle__jmataya__missingmigrants__0", "question": "I have a database of Missing Migrants Dataset. As a humanitarian aid organization, I want to allocate resources and support to regions with high incidents of missing migrants.", "description": "\n\nMissing Migrants Dataset\n\nMissingMigrantsProject\n1468 rows x 10 columns\n1. id | int64 | 1 | 3 | 4 | 6 | 7\n2. cause_of_death | object | Presumed drowning | Fell from train | Presumed drowning | Drowning | Vehicle accident\n3. region_origin | object | Middle East | Central America & Mexico | Middle East | MENA | South East Asia\n4. dead | float64 | 1.0 | 1.0 | 1.0 | 4.0 | 4.0\n5. incident_region | object | Mediterranean | Central America incl. Mexico | Mediterranean | Mediterranean | Southeast Asia\n6. date | object | 05/11/2015 | 03/11/2015 | 03/11/2015 | 01/11/2015 | 01/11/2015\n7. source | object | IOM Greece | La Jornada | Hellenic Coast Guard | Reuters | Phnom Penh Post\n8. reliability | object | Verified | Partially Verified | Verified | Partially Verified | Partially Verified\n9. lat | float64 | 36.8915 | 15.9564 | 36.50438994 | 37.2856 | 13.3611\n10. lon | float64 | 27.2877 | -93.6631 | 27.36325278 | 27.0866 | 100.985\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__jmataya__missingmigrants/MissingMigrantsProject.csv"]}
{"id": "kaggle__jmataya__missingmigrants__1", "question": "I have a database of Missing Migrants Dataset. As a government official, I want to develop policies and strategies to address the causes of death among missing migrants.", "description": "\n\nMissing Migrants Dataset\n\nMissingMigrantsProject\n1468 rows x 10 columns\n1. id | int64 | 1 | 3 | 4 | 6 | 7\n2. cause_of_death | object | Presumed drowning | Fell from train | Presumed drowning | Drowning | Vehicle accident\n3. region_origin | object | Middle East | Central America & Mexico | Middle East | MENA | South East Asia\n4. dead | float64 | 1.0 | 1.0 | 1.0 | 4.0 | 4.0\n5. incident_region | object | Mediterranean | Central America incl. Mexico | Mediterranean | Mediterranean | Southeast Asia\n6. date | object | 05/11/2015 | 03/11/2015 | 03/11/2015 | 01/11/2015 | 01/11/2015\n7. source | object | IOM Greece | La Jornada | Hellenic Coast Guard | Reuters | Phnom Penh Post\n8. reliability | object | Verified | Partially Verified | Verified | Partially Verified | Partially Verified\n9. lat | float64 | 36.8915 | 15.9564 | 36.50438994 | 37.2856 | 13.3611\n10. lon | float64 | 27.2877 | -93.6631 | 27.36325278 | 27.0866 | 100.985\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__jmataya__missingmigrants/MissingMigrantsProject.csv"]}
{"id": "kaggle__jmataya__missingmigrants__2", "question": "I have a database of Missing Migrants Dataset. As a humanitarian researcher, I want to analyze the data to identify trends and patterns in migration routes and incident regions.", "description": "\n\nMissing Migrants Dataset\n\nMissingMigrantsProject\n1468 rows x 10 columns\n1. id | int64 | 1 | 3 | 4 | 6 | 7\n2. cause_of_death | object | Presumed drowning | Fell from train | Presumed drowning | Drowning | Vehicle accident\n3. region_origin | object | Middle East | Central America & Mexico | Middle East | MENA | South East Asia\n4. dead | float64 | 1.0 | 1.0 | 1.0 | 4.0 | 4.0\n5. incident_region | object | Mediterranean | Central America incl. Mexico | Mediterranean | Mediterranean | Southeast Asia\n6. date | object | 05/11/2015 | 03/11/2015 | 03/11/2015 | 01/11/2015 | 01/11/2015\n7. source | object | IOM Greece | La Jornada | Hellenic Coast Guard | Reuters | Phnom Penh Post\n8. reliability | object | Verified | Partially Verified | Verified | Partially Verified | Partially Verified\n9. lat | float64 | 36.8915 | 15.9564 | 36.50438994 | 37.2856 | 13.3611\n10. lon | float64 | 27.2877 | -93.6631 | 27.36325278 | 27.0866 | 100.985\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__jmataya__missingmigrants/MissingMigrantsProject.csv"]}
{"id": "kaggle__jmataya__missingmigrants__3", "question": "I have a database of Missing Migrants Dataset. As a media organization, I want to use the data to raise awareness and advocate for improved migration policies and support.", "description": "\n\nMissing Migrants Dataset\n\nMissingMigrantsProject\n1468 rows x 10 columns\n1. id | int64 | 1 | 3 | 4 | 6 | 7\n2. cause_of_death | object | Presumed drowning | Fell from train | Presumed drowning | Drowning | Vehicle accident\n3. region_origin | object | Middle East | Central America & Mexico | Middle East | MENA | South East Asia\n4. dead | float64 | 1.0 | 1.0 | 1.0 | 4.0 | 4.0\n5. incident_region | object | Mediterranean | Central America incl. Mexico | Mediterranean | Mediterranean | Southeast Asia\n6. date | object | 05/11/2015 | 03/11/2015 | 03/11/2015 | 01/11/2015 | 01/11/2015\n7. source | object | IOM Greece | La Jornada | Hellenic Coast Guard | Reuters | Phnom Penh Post\n8. reliability | object | Verified | Partially Verified | Verified | Partially Verified | Partially Verified\n9. lat | float64 | 36.8915 | 15.9564 | 36.50438994 | 37.2856 | 13.3611\n10. lon | float64 | 27.2877 | -93.6631 | 27.36325278 | 27.0866 | 100.985\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__jmataya__missingmigrants/MissingMigrantsProject.csv"]}
{"id": "kaggle__jmataya__missingmigrants__4", "question": "I have a database of Missing Migrants Dataset. As a human rights advocate, I want to use the data to highlight and address issues of human trafficking and migrant exploitation.", "description": "\n\nMissing Migrants Dataset\n\nMissingMigrantsProject\n1468 rows x 10 columns\n1. id | int64 | 1 | 3 | 4 | 6 | 7\n2. cause_of_death | object | Presumed drowning | Fell from train | Presumed drowning | Drowning | Vehicle accident\n3. region_origin | object | Middle East | Central America & Mexico | Middle East | MENA | South East Asia\n4. dead | float64 | 1.0 | 1.0 | 1.0 | 4.0 | 4.0\n5. incident_region | object | Mediterranean | Central America incl. Mexico | Mediterranean | Mediterranean | Southeast Asia\n6. date | object | 05/11/2015 | 03/11/2015 | 03/11/2015 | 01/11/2015 | 01/11/2015\n7. source | object | IOM Greece | La Jornada | Hellenic Coast Guard | Reuters | Phnom Penh Post\n8. reliability | object | Verified | Partially Verified | Verified | Partially Verified | Partially Verified\n9. lat | float64 | 36.8915 | 15.9564 | 36.50438994 | 37.2856 | 13.3611\n10. lon | float64 | 27.2877 | -93.6631 | 27.36325278 | 27.0866 | 100.985\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__jmataya__missingmigrants/MissingMigrantsProject.csv"]}
{"id": "kaggle__jmataya__missingmigrants__5", "question": "I have a database of Missing Migrants Dataset. As a migration consultant, I want to analyze the data to provide evidence-based recommendations for safer migration routes.", "description": "\n\nMissing Migrants Dataset\n\nMissingMigrantsProject\n1468 rows x 10 columns\n1. id | int64 | 1 | 3 | 4 | 6 | 7\n2. cause_of_death | object | Presumed drowning | Fell from train | Presumed drowning | Drowning | Vehicle accident\n3. region_origin | object | Middle East | Central America & Mexico | Middle East | MENA | South East Asia\n4. dead | float64 | 1.0 | 1.0 | 1.0 | 4.0 | 4.0\n5. incident_region | object | Mediterranean | Central America incl. Mexico | Mediterranean | Mediterranean | Southeast Asia\n6. date | object | 05/11/2015 | 03/11/2015 | 03/11/2015 | 01/11/2015 | 01/11/2015\n7. source | object | IOM Greece | La Jornada | Hellenic Coast Guard | Reuters | Phnom Penh Post\n8. reliability | object | Verified | Partially Verified | Verified | Partially Verified | Partially Verified\n9. lat | float64 | 36.8915 | 15.9564 | 36.50438994 | 37.2856 | 13.3611\n10. lon | float64 | 27.2877 | -93.6631 | 27.36325278 | 27.0866 | 100.985\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__jmataya__missingmigrants/MissingMigrantsProject.csv"]}
{"id": "kaggle__jmataya__missingmigrants__6", "question": "I have a database of Missing Migrants Dataset. As a NGO working on search and rescue operations, I want to use the data to inform and prioritize search efforts.", "description": "\n\nMissing Migrants Dataset\n\nMissingMigrantsProject\n1468 rows x 10 columns\n1. id | int64 | 1 | 3 | 4 | 6 | 7\n2. cause_of_death | object | Presumed drowning | Fell from train | Presumed drowning | Drowning | Vehicle accident\n3. region_origin | object | Middle East | Central America & Mexico | Middle East | MENA | South East Asia\n4. dead | float64 | 1.0 | 1.0 | 1.0 | 4.0 | 4.0\n5. incident_region | object | Mediterranean | Central America incl. Mexico | Mediterranean | Mediterranean | Southeast Asia\n6. date | object | 05/11/2015 | 03/11/2015 | 03/11/2015 | 01/11/2015 | 01/11/2015\n7. source | object | IOM Greece | La Jornada | Hellenic Coast Guard | Reuters | Phnom Penh Post\n8. reliability | object | Verified | Partially Verified | Verified | Partially Verified | Partially Verified\n9. lat | float64 | 36.8915 | 15.9564 | 36.50438994 | 37.2856 | 13.3611\n10. lon | float64 | 27.2877 | -93.6631 | 27.36325278 | 27.0866 | 100.985\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__jmataya__missingmigrants/MissingMigrantsProject.csv"]}
{"id": "kaggle__jmataya__missingmigrants__7", "question": "I have a database of Missing Migrants Dataset. As a migration policy advisor, I want to analyze the data to make informed recommendations on policy changes and interventions.", "description": "\n\nMissing Migrants Dataset\n\nMissingMigrantsProject\n1468 rows x 10 columns\n1. id | int64 | 1 | 3 | 4 | 6 | 7\n2. cause_of_death | object | Presumed drowning | Fell from train | Presumed drowning | Drowning | Vehicle accident\n3. region_origin | object | Middle East | Central America & Mexico | Middle East | MENA | South East Asia\n4. dead | float64 | 1.0 | 1.0 | 1.0 | 4.0 | 4.0\n5. incident_region | object | Mediterranean | Central America incl. Mexico | Mediterranean | Mediterranean | Southeast Asia\n6. date | object | 05/11/2015 | 03/11/2015 | 03/11/2015 | 01/11/2015 | 01/11/2015\n7. source | object | IOM Greece | La Jornada | Hellenic Coast Guard | Reuters | Phnom Penh Post\n8. reliability | object | Verified | Partially Verified | Verified | Partially Verified | Partially Verified\n9. lat | float64 | 36.8915 | 15.9564 | 36.50438994 | 37.2856 | 13.3611\n10. lon | float64 | 27.2877 | -93.6631 | 27.36325278 | 27.0866 | 100.985\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__jmataya__missingmigrants/MissingMigrantsProject.csv"]}
{"id": "kaggle__michaelbryantds__electric-vehicle-charging-dataset__0", "question": "I have a database of Electric Vehicle Charging Dataset. As a government official, I want to determine where to allocate funds for the development of public charging stations.", "description": "\n\nElectric Vehicle Charging Dataset\n\nstation_data_dataverse\n2330 rows x 24 columns\n1. sessionId | int64 | 7093670 | 3730551 | 7080329 | 3829635 | 6139758\n2. kwhTotal | float64 | 5.61 | 9.03 | 6.95 | 7.38 | 6.69\n3. dollars | float64 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0\n4. created | object | 0014-11-18 15:01:17 | 0014-11-19 19:01:41 | 0014-11-20 19:20:45 | 0014-11-21 19:02:04 | 0014-11-24 17:16:19\n5. ended | object | 0014-11-18 18:26:04 | 0014-11-19 22:10:06 | 0014-11-20 21:48:04 | 0014-11-21 21:31:03 | 0014-11-24 19:31:04\n6. startTime | int64 | 15 | 19 | 19 | 19 | 17\n7. endTime | int64 | 18 | 22 | 21 | 21 | 19\n8. chargeTimeHrs | float64 | 3.413055556 | 3.140277778 | 2.455277778 | 2.483055556 | 2.245833333\n9. weekday | object | Tue | Wed | Thu | Fri | Mon\n10. platform | object | ios | ios | ios | ios | ios\n11. distance | float64 | 20.695727 | 20.695727 | 20.695727 | 20.695727 | 20.695727\n12. userId | int64 | 30828105 | 30828105 | 30828105 | 30828105 | 30828105\n13. stationId | int64 | 632920 | 569889 | 612116 | 549414 | 129465\n14. locationId | int64 | 461655 | 461655 | 461655 | 461655 | 461655\n15. managerVehicle | int64 | 0 | 0 | 0 | 0 | 0\n16. facilityType | int64 | 3 | 3 | 3 | 3 | 3\n17. Mon | int64 | 0 | 0 | 0 | 0 | 1\n18. Tues | int64 | 1 | 0 | 0 | 0 | 0\n19. Wed | int64 | 0 | 1 | 0 | 0 | 0\n20. Thurs | int64 | 0 | 0 | 1 | 0 | 0\n21. Fri | int64 | 0 | 0 | 0 | 1 | 0\n22. Sat | int64 | 0 | 0 | 0 | 0 | 0\n23. Sun | int64 | 0 | 0 | 0 | 0 | 0\n24. reportedZip | int64 | 1 | 1 | 1 | 1 | 1\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__michaelbryantds__electric-vehicle-charging-dataset/station_data_dataverse.csv"]}
{"id": "kaggle__michaelbryantds__electric-vehicle-charging-dataset__1", "question": "I have a database of Electric Vehicle Charging Dataset. As a car manufacturer, I want to identify areas with high EV adoption to target for marketing and sales efforts.", "description": "\n\nElectric Vehicle Charging Dataset\n\nstation_data_dataverse\n2330 rows x 24 columns\n1. sessionId | int64 | 7093670 | 3730551 | 7080329 | 3829635 | 6139758\n2. kwhTotal | float64 | 5.61 | 9.03 | 6.95 | 7.38 | 6.69\n3. dollars | float64 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0\n4. created | object | 0014-11-18 15:01:17 | 0014-11-19 19:01:41 | 0014-11-20 19:20:45 | 0014-11-21 19:02:04 | 0014-11-24 17:16:19\n5. ended | object | 0014-11-18 18:26:04 | 0014-11-19 22:10:06 | 0014-11-20 21:48:04 | 0014-11-21 21:31:03 | 0014-11-24 19:31:04\n6. startTime | int64 | 15 | 19 | 19 | 19 | 17\n7. endTime | int64 | 18 | 22 | 21 | 21 | 19\n8. chargeTimeHrs | float64 | 3.413055556 | 3.140277778 | 2.455277778 | 2.483055556 | 2.245833333\n9. weekday | object | Tue | Wed | Thu | Fri | Mon\n10. platform | object | ios | ios | ios | ios | ios\n11. distance | float64 | 20.695727 | 20.695727 | 20.695727 | 20.695727 | 20.695727\n12. userId | int64 | 30828105 | 30828105 | 30828105 | 30828105 | 30828105\n13. stationId | int64 | 632920 | 569889 | 612116 | 549414 | 129465\n14. locationId | int64 | 461655 | 461655 | 461655 | 461655 | 461655\n15. managerVehicle | int64 | 0 | 0 | 0 | 0 | 0\n16. facilityType | int64 | 3 | 3 | 3 | 3 | 3\n17. Mon | int64 | 0 | 0 | 0 | 0 | 1\n18. Tues | int64 | 1 | 0 | 0 | 0 | 0\n19. Wed | int64 | 0 | 1 | 0 | 0 | 0\n20. Thurs | int64 | 0 | 0 | 1 | 0 | 0\n21. Fri | int64 | 0 | 0 | 0 | 1 | 0\n22. Sat | int64 | 0 | 0 | 0 | 0 | 0\n23. Sun | int64 | 0 | 0 | 0 | 0 | 0\n24. reportedZip | int64 | 1 | 1 | 1 | 1 | 1\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__michaelbryantds__electric-vehicle-charging-dataset/station_data_dataverse.csv"]}
{"id": "kaggle__michaelbryantds__electric-vehicle-charging-dataset__2", "question": "I have a database of Electric Vehicle Charging Dataset. As an urban planner, I want to assess the need for charging infrastructure in different neighborhoods and plan accordingly.", "description": "\n\nElectric Vehicle Charging Dataset\n\nstation_data_dataverse\n2330 rows x 24 columns\n1. sessionId | int64 | 7093670 | 3730551 | 7080329 | 3829635 | 6139758\n2. kwhTotal | float64 | 5.61 | 9.03 | 6.95 | 7.38 | 6.69\n3. dollars | float64 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0\n4. created | object | 0014-11-18 15:01:17 | 0014-11-19 19:01:41 | 0014-11-20 19:20:45 | 0014-11-21 19:02:04 | 0014-11-24 17:16:19\n5. ended | object | 0014-11-18 18:26:04 | 0014-11-19 22:10:06 | 0014-11-20 21:48:04 | 0014-11-21 21:31:03 | 0014-11-24 19:31:04\n6. startTime | int64 | 15 | 19 | 19 | 19 | 17\n7. endTime | int64 | 18 | 22 | 21 | 21 | 19\n8. chargeTimeHrs | float64 | 3.413055556 | 3.140277778 | 2.455277778 | 2.483055556 | 2.245833333\n9. weekday | object | Tue | Wed | Thu | Fri | Mon\n10. platform | object | ios | ios | ios | ios | ios\n11. distance | float64 | 20.695727 | 20.695727 | 20.695727 | 20.695727 | 20.695727\n12. userId | int64 | 30828105 | 30828105 | 30828105 | 30828105 | 30828105\n13. stationId | int64 | 632920 | 569889 | 612116 | 549414 | 129465\n14. locationId | int64 | 461655 | 461655 | 461655 | 461655 | 461655\n15. managerVehicle | int64 | 0 | 0 | 0 | 0 | 0\n16. facilityType | int64 | 3 | 3 | 3 | 3 | 3\n17. Mon | int64 | 0 | 0 | 0 | 0 | 1\n18. Tues | int64 | 1 | 0 | 0 | 0 | 0\n19. Wed | int64 | 0 | 1 | 0 | 0 | 0\n20. Thurs | int64 | 0 | 0 | 1 | 0 | 0\n21. Fri | int64 | 0 | 0 | 0 | 1 | 0\n22. Sat | int64 | 0 | 0 | 0 | 0 | 0\n23. Sun | int64 | 0 | 0 | 0 | 0 | 0\n24. reportedZip | int64 | 1 | 1 | 1 | 1 | 1\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__michaelbryantds__electric-vehicle-charging-dataset/station_data_dataverse.csv"]}
{"id": "kaggle__michaelbryantds__electric-vehicle-charging-dataset__3", "question": "I have a database of Electric Vehicle Charging Dataset. As a fleet manager, I want to analyze charging patterns to optimize the charging schedule and minimize downtime for electric vehicles.", "description": "\n\nElectric Vehicle Charging Dataset\n\nstation_data_dataverse\n2330 rows x 24 columns\n1. sessionId | int64 | 7093670 | 3730551 | 7080329 | 3829635 | 6139758\n2. kwhTotal | float64 | 5.61 | 9.03 | 6.95 | 7.38 | 6.69\n3. dollars | float64 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0\n4. created | object | 0014-11-18 15:01:17 | 0014-11-19 19:01:41 | 0014-11-20 19:20:45 | 0014-11-21 19:02:04 | 0014-11-24 17:16:19\n5. ended | object | 0014-11-18 18:26:04 | 0014-11-19 22:10:06 | 0014-11-20 21:48:04 | 0014-11-21 21:31:03 | 0014-11-24 19:31:04\n6. startTime | int64 | 15 | 19 | 19 | 19 | 17\n7. endTime | int64 | 18 | 22 | 21 | 21 | 19\n8. chargeTimeHrs | float64 | 3.413055556 | 3.140277778 | 2.455277778 | 2.483055556 | 2.245833333\n9. weekday | object | Tue | Wed | Thu | Fri | Mon\n10. platform | object | ios | ios | ios | ios | ios\n11. distance | float64 | 20.695727 | 20.695727 | 20.695727 | 20.695727 | 20.695727\n12. userId | int64 | 30828105 | 30828105 | 30828105 | 30828105 | 30828105\n13. stationId | int64 | 632920 | 569889 | 612116 | 549414 | 129465\n14. locationId | int64 | 461655 | 461655 | 461655 | 461655 | 461655\n15. managerVehicle | int64 | 0 | 0 | 0 | 0 | 0\n16. facilityType | int64 | 3 | 3 | 3 | 3 | 3\n17. Mon | int64 | 0 | 0 | 0 | 0 | 1\n18. Tues | int64 | 1 | 0 | 0 | 0 | 0\n19. Wed | int64 | 0 | 1 | 0 | 0 | 0\n20. Thurs | int64 | 0 | 0 | 1 | 0 | 0\n21. Fri | int64 | 0 | 0 | 0 | 1 | 0\n22. Sat | int64 | 0 | 0 | 0 | 0 | 0\n23. Sun | int64 | 0 | 0 | 0 | 0 | 0\n24. reportedZip | int64 | 1 | 1 | 1 | 1 | 1\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__michaelbryantds__electric-vehicle-charging-dataset/station_data_dataverse.csv"]}
{"id": "kaggle__michaelbryantds__electric-vehicle-charging-dataset__4", "question": "I have a database of Electric Vehicle Charging Dataset. As an environmentalist, I want to assess the environmental impact of EV charging and promote sustainable practices.", "description": "\n\nElectric Vehicle Charging Dataset\n\nstation_data_dataverse\n2330 rows x 24 columns\n1. sessionId | int64 | 7093670 | 3730551 | 7080329 | 3829635 | 6139758\n2. kwhTotal | float64 | 5.61 | 9.03 | 6.95 | 7.38 | 6.69\n3. dollars | float64 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0\n4. created | object | 0014-11-18 15:01:17 | 0014-11-19 19:01:41 | 0014-11-20 19:20:45 | 0014-11-21 19:02:04 | 0014-11-24 17:16:19\n5. ended | object | 0014-11-18 18:26:04 | 0014-11-19 22:10:06 | 0014-11-20 21:48:04 | 0014-11-21 21:31:03 | 0014-11-24 19:31:04\n6. startTime | int64 | 15 | 19 | 19 | 19 | 17\n7. endTime | int64 | 18 | 22 | 21 | 21 | 19\n8. chargeTimeHrs | float64 | 3.413055556 | 3.140277778 | 2.455277778 | 2.483055556 | 2.245833333\n9. weekday | object | Tue | Wed | Thu | Fri | Mon\n10. platform | object | ios | ios | ios | ios | ios\n11. distance | float64 | 20.695727 | 20.695727 | 20.695727 | 20.695727 | 20.695727\n12. userId | int64 | 30828105 | 30828105 | 30828105 | 30828105 | 30828105\n13. stationId | int64 | 632920 | 569889 | 612116 | 549414 | 129465\n14. locationId | int64 | 461655 | 461655 | 461655 | 461655 | 461655\n15. managerVehicle | int64 | 0 | 0 | 0 | 0 | 0\n16. facilityType | int64 | 3 | 3 | 3 | 3 | 3\n17. Mon | int64 | 0 | 0 | 0 | 0 | 1\n18. Tues | int64 | 1 | 0 | 0 | 0 | 0\n19. Wed | int64 | 0 | 1 | 0 | 0 | 0\n20. Thurs | int64 | 0 | 0 | 1 | 0 | 0\n21. Fri | int64 | 0 | 0 | 0 | 1 | 0\n22. Sat | int64 | 0 | 0 | 0 | 0 | 0\n23. Sun | int64 | 0 | 0 | 0 | 0 | 0\n24. reportedZip | int64 | 1 | 1 | 1 | 1 | 1\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__michaelbryantds__electric-vehicle-charging-dataset/station_data_dataverse.csv"]}
{"id": "kaggle__michaelbryantds__electric-vehicle-charging-dataset__5", "question": "I have a database of Electric Vehicle Charging Dataset. As a research analyst, I want to study the trends and patterns in EV charging behavior to contribute to academic research.", "description": "\n\nElectric Vehicle Charging Dataset\n\nstation_data_dataverse\n2330 rows x 24 columns\n1. sessionId | int64 | 7093670 | 3730551 | 7080329 | 3829635 | 6139758\n2. kwhTotal | float64 | 5.61 | 9.03 | 6.95 | 7.38 | 6.69\n3. dollars | float64 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0\n4. created | object | 0014-11-18 15:01:17 | 0014-11-19 19:01:41 | 0014-11-20 19:20:45 | 0014-11-21 19:02:04 | 0014-11-24 17:16:19\n5. ended | object | 0014-11-18 18:26:04 | 0014-11-19 22:10:06 | 0014-11-20 21:48:04 | 0014-11-21 21:31:03 | 0014-11-24 19:31:04\n6. startTime | int64 | 15 | 19 | 19 | 19 | 17\n7. endTime | int64 | 18 | 22 | 21 | 21 | 19\n8. chargeTimeHrs | float64 | 3.413055556 | 3.140277778 | 2.455277778 | 2.483055556 | 2.245833333\n9. weekday | object | Tue | Wed | Thu | Fri | Mon\n10. platform | object | ios | ios | ios | ios | ios\n11. distance | float64 | 20.695727 | 20.695727 | 20.695727 | 20.695727 | 20.695727\n12. userId | int64 | 30828105 | 30828105 | 30828105 | 30828105 | 30828105\n13. stationId | int64 | 632920 | 569889 | 612116 | 549414 | 129465\n14. locationId | int64 | 461655 | 461655 | 461655 | 461655 | 461655\n15. managerVehicle | int64 | 0 | 0 | 0 | 0 | 0\n16. facilityType | int64 | 3 | 3 | 3 | 3 | 3\n17. Mon | int64 | 0 | 0 | 0 | 0 | 1\n18. Tues | int64 | 1 | 0 | 0 | 0 | 0\n19. Wed | int64 | 0 | 1 | 0 | 0 | 0\n20. Thurs | int64 | 0 | 0 | 1 | 0 | 0\n21. Fri | int64 | 0 | 0 | 0 | 1 | 0\n22. Sat | int64 | 0 | 0 | 0 | 0 | 0\n23. Sun | int64 | 0 | 0 | 0 | 0 | 0\n24. reportedZip | int64 | 1 | 1 | 1 | 1 | 1\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__michaelbryantds__electric-vehicle-charging-dataset/station_data_dataverse.csv"]}
{"id": "kaggle__michau96__restaurant-business-rankings-2020__1", "question": "I have a database of Restaurant Business Rankings 2020. As an investor, I want to study the rankings and sales figures of each restaurant category to decide which businesses to invest in.", "description": "\n\nRestaurant Business Rankings 2020\n\nFuture50\n50 rows x 9 columns\n1. Rank | int64 | 1 | 2 | 3 | 4 | 5\n2. Restaurant | object | Evergreens | Clean Juice | Slapfish | Clean Eatz | Pokeworks\n3. Location | object | Seattle, Wash. | Charlotte, N.C. | Huntington Beach, Calif. | Wilmington, N.C. | Irvine, Calif.\n4. Sales | int64 | 24 | 44 | 21 | 25 | 49\n5. YOY_Sales | object | 130.5% | 121.9% | 81.0% | 79.7% | 77.1%\n6. Units | int64 | 26 | 105 | 21 | 46 | 50\n7. YOY_Units | object | 116.7% | 94.4% | 90.9% | 58.6% | 56.3%\n8. Unit_Volume | int64 | 1150 | 560 | 1370 | 685 | 1210\n9. Franchising | object | No | Yes | Yes | Yes | Yes\n\nIndependence100\n100 rows x 7 columns\n1. Rank | int64 | 1 | 2 | 3 | 4 | 5\n2. Restaurant | object | Carmine's (Times Square) | The Boathouse Orlando | Old Ebbitt Grill | LAVO Italian Restaurant & Nightclub | Bryant Park Grill & Cafe\n3. Sales | float64 | 39080335.0 | 35218364.0 | 29104017.0 | 26916180.0 | 26900000.0\n4. Average Check | int64 | 40 | 43 | 33 | 90 | 62\n5. City | object | New York | Orlando  | Washington | New York | New York\n6. State | object | N.Y. | Fla. | D.C. | N.Y. | N.Y.\n7. Meals Served | float64 | 469803.0 | 820819.0 | 892830.0 | 198500.0 | 403000.0\n\nTop250\n250 rows x 7 columns\n1. Rank | int64 | 1 | 2 | 3 | 4 | 5\n2. Restaurant | object | McDonald's | Starbucks | Chick-fil-A | Taco Bell | Burger King\n3. Sales | int64 | 40412 | 21380 | 11320 | 11293 | 10204\n4. YOY_Sales | object | 4.9% | 8.6% | 13.0% | 9.0% | 2.7%\n5. Units | int64 | 13846 | 15049 | 2470 | 6766 | 7346\n6. YOY_Units | object | -0.5% | 3.0% | 5.0% | 2.7% | 0.2%\n7. Segment_Category | object | Quick Service & Burger | Quick Service & Coffee Cafe | Quick Service & Chicken | Quick Service & Mexican | Quick Service & Burger\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__michau96__restaurant-business-rankings-2020/Future50.csv", "csv/kaggle__michau96__restaurant-business-rankings-2020/Independence100.csv", "csv/kaggle__michau96__restaurant-business-rankings-2020/Top250.csv"]}
{"id": "kaggle__michau96__restaurant-business-rankings-2020__3", "question": "I have a database of Restaurant Business Rankings 2020. As a restaurant supply chain manager, I want to analyze the sales figures for each restaurant category to make purchasing and production decisions.", "description": "\n\nRestaurant Business Rankings 2020\n\nFuture50\n50 rows x 9 columns\n1. Rank | int64 | 1 | 2 | 3 | 4 | 5\n2. Restaurant | object | Evergreens | Clean Juice | Slapfish | Clean Eatz | Pokeworks\n3. Location | object | Seattle, Wash. | Charlotte, N.C. | Huntington Beach, Calif. | Wilmington, N.C. | Irvine, Calif.\n4. Sales | int64 | 24 | 44 | 21 | 25 | 49\n5. YOY_Sales | object | 130.5% | 121.9% | 81.0% | 79.7% | 77.1%\n6. Units | int64 | 26 | 105 | 21 | 46 | 50\n7. YOY_Units | object | 116.7% | 94.4% | 90.9% | 58.6% | 56.3%\n8. Unit_Volume | int64 | 1150 | 560 | 1370 | 685 | 1210\n9. Franchising | object | No | Yes | Yes | Yes | Yes\n\nIndependence100\n100 rows x 7 columns\n1. Rank | int64 | 1 | 2 | 3 | 4 | 5\n2. Restaurant | object | Carmine's (Times Square) | The Boathouse Orlando | Old Ebbitt Grill | LAVO Italian Restaurant & Nightclub | Bryant Park Grill & Cafe\n3. Sales | float64 | 39080335.0 | 35218364.0 | 29104017.0 | 26916180.0 | 26900000.0\n4. Average Check | int64 | 40 | 43 | 33 | 90 | 62\n5. City | object | New York | Orlando  | Washington | New York | New York\n6. State | object | N.Y. | Fla. | D.C. | N.Y. | N.Y.\n7. Meals Served | float64 | 469803.0 | 820819.0 | 892830.0 | 198500.0 | 403000.0\n\nTop250\n250 rows x 7 columns\n1. Rank | int64 | 1 | 2 | 3 | 4 | 5\n2. Restaurant | object | McDonald's | Starbucks | Chick-fil-A | Taco Bell | Burger King\n3. Sales | int64 | 40412 | 21380 | 11320 | 11293 | 10204\n4. YOY_Sales | object | 4.9% | 8.6% | 13.0% | 9.0% | 2.7%\n5. Units | int64 | 13846 | 15049 | 2470 | 6766 | 7346\n6. YOY_Units | object | -0.5% | 3.0% | 5.0% | 2.7% | 0.2%\n7. Segment_Category | object | Quick Service & Burger | Quick Service & Coffee Cafe | Quick Service & Chicken | Quick Service & Mexican | Quick Service & Burger\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__michau96__restaurant-business-rankings-2020/Future50.csv", "csv/kaggle__michau96__restaurant-business-rankings-2020/Independence100.csv", "csv/kaggle__michau96__restaurant-business-rankings-2020/Top250.csv"]}
{"id": "kaggle__michau96__restaurant-business-rankings-2020__5", "question": "I have a database of Restaurant Business Rankings 2020. As a journalist, I want to write reports about the most successful restaurants and new restaurant trends based on the Future50 and Independence100 tables.", "description": "\n\nRestaurant Business Rankings 2020\n\nFuture50\n50 rows x 9 columns\n1. Rank | int64 | 1 | 2 | 3 | 4 | 5\n2. Restaurant | object | Evergreens | Clean Juice | Slapfish | Clean Eatz | Pokeworks\n3. Location | object | Seattle, Wash. | Charlotte, N.C. | Huntington Beach, Calif. | Wilmington, N.C. | Irvine, Calif.\n4. Sales | int64 | 24 | 44 | 21 | 25 | 49\n5. YOY_Sales | object | 130.5% | 121.9% | 81.0% | 79.7% | 77.1%\n6. Units | int64 | 26 | 105 | 21 | 46 | 50\n7. YOY_Units | object | 116.7% | 94.4% | 90.9% | 58.6% | 56.3%\n8. Unit_Volume | int64 | 1150 | 560 | 1370 | 685 | 1210\n9. Franchising | object | No | Yes | Yes | Yes | Yes\n\nIndependence100\n100 rows x 7 columns\n1. Rank | int64 | 1 | 2 | 3 | 4 | 5\n2. Restaurant | object | Carmine's (Times Square) | The Boathouse Orlando | Old Ebbitt Grill | LAVO Italian Restaurant & Nightclub | Bryant Park Grill & Cafe\n3. Sales | float64 | 39080335.0 | 35218364.0 | 29104017.0 | 26916180.0 | 26900000.0\n4. Average Check | int64 | 40 | 43 | 33 | 90 | 62\n5. City | object | New York | Orlando  | Washington | New York | New York\n6. State | object | N.Y. | Fla. | D.C. | N.Y. | N.Y.\n7. Meals Served | float64 | 469803.0 | 820819.0 | 892830.0 | 198500.0 | 403000.0\n\nTop250\n250 rows x 7 columns\n1. Rank | int64 | 1 | 2 | 3 | 4 | 5\n2. Restaurant | object | McDonald's | Starbucks | Chick-fil-A | Taco Bell | Burger King\n3. Sales | int64 | 40412 | 21380 | 11320 | 11293 | 10204\n4. YOY_Sales | object | 4.9% | 8.6% | 13.0% | 9.0% | 2.7%\n5. Units | int64 | 13846 | 15049 | 2470 | 6766 | 7346\n6. YOY_Units | object | -0.5% | 3.0% | 5.0% | 2.7% | 0.2%\n7. Segment_Category | object | Quick Service & Burger | Quick Service & Coffee Cafe | Quick Service & Chicken | Quick Service & Mexican | Quick Service & Burger\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__michau96__restaurant-business-rankings-2020/Future50.csv", "csv/kaggle__michau96__restaurant-business-rankings-2020/Independence100.csv", "csv/kaggle__michau96__restaurant-business-rankings-2020/Top250.csv"]}
{"id": "kaggle__divyeshardeshana__supply-chain-shipment-pricing-data__0", "question": "I have a database of Supply Chain Shipment Pricing Data. As a logistics coordinator, I want to identify patterns in shipment pricing data to optimize transportation routes and modes.", "description": "\n\nSupply Chain Shipment Pricing Data\n\nSCMS_Delivery_History_Dataset\n8158 rows x 32 columns\n1. ID | int64 | 108 | 115 | 116 | 161 | 269\n2. Project Code | object | 104-CI-T01 | 108-VN-T01 | 108-VN-T01 | 117-ET-T01 | 108-VN-T01\n3. PQ # | object | Pre-PQ Process | Pre-PQ Process | Pre-PQ Process | Pre-PQ Process | Pre-PQ Process\n4. PO / SO # | object | SCMS-698 | SCMS-753 | SCMS-759 | SCMS-11070 | SCMS-14190\n5. ASN/DN # | object | ASN-727 | ASN-781 | ASN-632 | ASN-916 | ASN-1192\n6. Country | object | C√¥te d'Ivoire | Vietnam | Vietnam | Ethiopia | Vietnam\n7. Managed By | object | PMO - US | PMO - US | PMO - US | PMO - US | PMO - US\n8. Fulfill Via | object | Direct Drop | Direct Drop | Direct Drop | Direct Drop | Direct Drop\n9. Vendor INCO Term | object | CIP | EXW | FCA | EXW | EXW\n10. Shipment Mode | object | Air | Air | Air | Air | Air\n11. PQ First Sent to Client Date | object | Pre-PQ Process | Pre-PQ Process | Pre-PQ Process | Pre-PQ Process | Pre-PQ Process\n12. PO Sent to Vendor Date | object | 7/13/07 | 7/4/07 | 7/4/07 | 10/3/07 | 11/19/07\n13. Scheduled Delivery Date | object | 2-Oct-07 | 15-Oct-07 | 27-Aug-07 | 20-Nov-07 | 21-Jan-08\n14. Delivered to Client Date | object | 2-Oct-07 | 15-Oct-07 | 27-Aug-07 | 20-Nov-07 | 21-Jan-08\n15. Delivery Recorded Date | object | 2-Oct-07 | 15-Oct-07 | 27-Aug-07 | 20-Nov-07 | 21-Jan-08\n16. Product Group | object | ARV | ARV | ARV | ARV | ARV\n17. Sub Classification | object | Pediatric | Pediatric | Adult | Adult | Adult\n18. Vendor | object | BRISTOL-MYERS SQUIBB | Aurobindo Pharma Limited | ABBVIE LOGISTICS (FORMERLY ABBOTT LOGISTICS BV) | Aurobindo Pharma Limited | GILEAD SCIENCES IRELAND, INC.\n19. Molecule/Test Type | object | Didanosine | Nevirapine | Lopinavir/Ritonavir | Stavudine | Tenofovir Disoproxil Fumarate\n20. Brand | object | Videx | Generic | Aluvia | Generic | Viread\n21. Dosage | object | 200mg | 10mg/ml | 200/50mg | 30mg | 300mg\n22. Dosage Form | object | Tablet | Oral suspension | Tablet | Capsule | Tablet\n23. Unit of Measure (Per Pack) | int64 | 60 | 240 | 120 | 60 | 30\n24. Line Item Quantity | int64 | 5513 | 1000 | 500 | 64000 | 1000\n25. Line Item Value | float64 | 140581.5 | 1920.0 | 41095.0 | 99200.0 | 17000.0\n26. Pack Price | float64 | 25.5 | 1.92 | 82.19 | 1.55 | 17.0\n27. Unit Price | float64 | 0.42 | 0.01 | 0.68 | 0.03 | 0.57\n28. Manufacturing Site | object | BMS Meymac, France | Aurobindo Unit III, India | ABBVIE Ludwigshafen Germany | Aurobindo Unit III, India | Gilead(Nycomed) Oranienburg DE\n29. First Line Designation | object | Yes | Yes | Yes | Yes | Yes\n30. Weight (Kilograms) | object | 2126 | 941 | 117 | 4228 | 76\n31. Freight Cost (USD) | object | Freight Included in Commodity Cost | 4193.49 | 1767.38 | 12237.61 | 2282.57\n32. Line Item Insurance (USD) | float64 | 224.93 | 3.07 | 65.75 | 158.72 | 27.2\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__divyeshardeshana__supply-chain-shipment-pricing-data/SCMS_Delivery_History_Dataset.csv"]}
{"id": "kaggle__divyeshardeshana__supply-chain-shipment-pricing-data__1", "question": "I have a database of Supply Chain Shipment Pricing Data. As a operations director, I want to evaluate the shipment pricing data to make decisions on warehouse capacity and inventory management.", "description": "\n\nSupply Chain Shipment Pricing Data\n\nSCMS_Delivery_History_Dataset\n8158 rows x 32 columns\n1. ID | int64 | 108 | 115 | 116 | 161 | 269\n2. Project Code | object | 104-CI-T01 | 108-VN-T01 | 108-VN-T01 | 117-ET-T01 | 108-VN-T01\n3. PQ # | object | Pre-PQ Process | Pre-PQ Process | Pre-PQ Process | Pre-PQ Process | Pre-PQ Process\n4. PO / SO # | object | SCMS-698 | SCMS-753 | SCMS-759 | SCMS-11070 | SCMS-14190\n5. ASN/DN # | object | ASN-727 | ASN-781 | ASN-632 | ASN-916 | ASN-1192\n6. Country | object | C√¥te d'Ivoire | Vietnam | Vietnam | Ethiopia | Vietnam\n7. Managed By | object | PMO - US | PMO - US | PMO - US | PMO - US | PMO - US\n8. Fulfill Via | object | Direct Drop | Direct Drop | Direct Drop | Direct Drop | Direct Drop\n9. Vendor INCO Term | object | CIP | EXW | FCA | EXW | EXW\n10. Shipment Mode | object | Air | Air | Air | Air | Air\n11. PQ First Sent to Client Date | object | Pre-PQ Process | Pre-PQ Process | Pre-PQ Process | Pre-PQ Process | Pre-PQ Process\n12. PO Sent to Vendor Date | object | 7/13/07 | 7/4/07 | 7/4/07 | 10/3/07 | 11/19/07\n13. Scheduled Delivery Date | object | 2-Oct-07 | 15-Oct-07 | 27-Aug-07 | 20-Nov-07 | 21-Jan-08\n14. Delivered to Client Date | object | 2-Oct-07 | 15-Oct-07 | 27-Aug-07 | 20-Nov-07 | 21-Jan-08\n15. Delivery Recorded Date | object | 2-Oct-07 | 15-Oct-07 | 27-Aug-07 | 20-Nov-07 | 21-Jan-08\n16. Product Group | object | ARV | ARV | ARV | ARV | ARV\n17. Sub Classification | object | Pediatric | Pediatric | Adult | Adult | Adult\n18. Vendor | object | BRISTOL-MYERS SQUIBB | Aurobindo Pharma Limited | ABBVIE LOGISTICS (FORMERLY ABBOTT LOGISTICS BV) | Aurobindo Pharma Limited | GILEAD SCIENCES IRELAND, INC.\n19. Molecule/Test Type | object | Didanosine | Nevirapine | Lopinavir/Ritonavir | Stavudine | Tenofovir Disoproxil Fumarate\n20. Brand | object | Videx | Generic | Aluvia | Generic | Viread\n21. Dosage | object | 200mg | 10mg/ml | 200/50mg | 30mg | 300mg\n22. Dosage Form | object | Tablet | Oral suspension | Tablet | Capsule | Tablet\n23. Unit of Measure (Per Pack) | int64 | 60 | 240 | 120 | 60 | 30\n24. Line Item Quantity | int64 | 5513 | 1000 | 500 | 64000 | 1000\n25. Line Item Value | float64 | 140581.5 | 1920.0 | 41095.0 | 99200.0 | 17000.0\n26. Pack Price | float64 | 25.5 | 1.92 | 82.19 | 1.55 | 17.0\n27. Unit Price | float64 | 0.42 | 0.01 | 0.68 | 0.03 | 0.57\n28. Manufacturing Site | object | BMS Meymac, France | Aurobindo Unit III, India | ABBVIE Ludwigshafen Germany | Aurobindo Unit III, India | Gilead(Nycomed) Oranienburg DE\n29. First Line Designation | object | Yes | Yes | Yes | Yes | Yes\n30. Weight (Kilograms) | object | 2126 | 941 | 117 | 4228 | 76\n31. Freight Cost (USD) | object | Freight Included in Commodity Cost | 4193.49 | 1767.38 | 12237.61 | 2282.57\n32. Line Item Insurance (USD) | float64 | 224.93 | 3.07 | 65.75 | 158.72 | 27.2\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__divyeshardeshana__supply-chain-shipment-pricing-data/SCMS_Delivery_History_Dataset.csv"]}
{"id": "kaggle__divyeshardeshana__supply-chain-shipment-pricing-data__2", "question": "I have a database of Supply Chain Shipment Pricing Data. As a sales manager, I want to analyze the shipment pricing data to determine the profitability of specific products or customer segments.", "description": "\n\nSupply Chain Shipment Pricing Data\n\nSCMS_Delivery_History_Dataset\n8158 rows x 32 columns\n1. ID | int64 | 108 | 115 | 116 | 161 | 269\n2. Project Code | object | 104-CI-T01 | 108-VN-T01 | 108-VN-T01 | 117-ET-T01 | 108-VN-T01\n3. PQ # | object | Pre-PQ Process | Pre-PQ Process | Pre-PQ Process | Pre-PQ Process | Pre-PQ Process\n4. PO / SO # | object | SCMS-698 | SCMS-753 | SCMS-759 | SCMS-11070 | SCMS-14190\n5. ASN/DN # | object | ASN-727 | ASN-781 | ASN-632 | ASN-916 | ASN-1192\n6. Country | object | C√¥te d'Ivoire | Vietnam | Vietnam | Ethiopia | Vietnam\n7. Managed By | object | PMO - US | PMO - US | PMO - US | PMO - US | PMO - US\n8. Fulfill Via | object | Direct Drop | Direct Drop | Direct Drop | Direct Drop | Direct Drop\n9. Vendor INCO Term | object | CIP | EXW | FCA | EXW | EXW\n10. Shipment Mode | object | Air | Air | Air | Air | Air\n11. PQ First Sent to Client Date | object | Pre-PQ Process | Pre-PQ Process | Pre-PQ Process | Pre-PQ Process | Pre-PQ Process\n12. PO Sent to Vendor Date | object | 7/13/07 | 7/4/07 | 7/4/07 | 10/3/07 | 11/19/07\n13. Scheduled Delivery Date | object | 2-Oct-07 | 15-Oct-07 | 27-Aug-07 | 20-Nov-07 | 21-Jan-08\n14. Delivered to Client Date | object | 2-Oct-07 | 15-Oct-07 | 27-Aug-07 | 20-Nov-07 | 21-Jan-08\n15. Delivery Recorded Date | object | 2-Oct-07 | 15-Oct-07 | 27-Aug-07 | 20-Nov-07 | 21-Jan-08\n16. Product Group | object | ARV | ARV | ARV | ARV | ARV\n17. Sub Classification | object | Pediatric | Pediatric | Adult | Adult | Adult\n18. Vendor | object | BRISTOL-MYERS SQUIBB | Aurobindo Pharma Limited | ABBVIE LOGISTICS (FORMERLY ABBOTT LOGISTICS BV) | Aurobindo Pharma Limited | GILEAD SCIENCES IRELAND, INC.\n19. Molecule/Test Type | object | Didanosine | Nevirapine | Lopinavir/Ritonavir | Stavudine | Tenofovir Disoproxil Fumarate\n20. Brand | object | Videx | Generic | Aluvia | Generic | Viread\n21. Dosage | object | 200mg | 10mg/ml | 200/50mg | 30mg | 300mg\n22. Dosage Form | object | Tablet | Oral suspension | Tablet | Capsule | Tablet\n23. Unit of Measure (Per Pack) | int64 | 60 | 240 | 120 | 60 | 30\n24. Line Item Quantity | int64 | 5513 | 1000 | 500 | 64000 | 1000\n25. Line Item Value | float64 | 140581.5 | 1920.0 | 41095.0 | 99200.0 | 17000.0\n26. Pack Price | float64 | 25.5 | 1.92 | 82.19 | 1.55 | 17.0\n27. Unit Price | float64 | 0.42 | 0.01 | 0.68 | 0.03 | 0.57\n28. Manufacturing Site | object | BMS Meymac, France | Aurobindo Unit III, India | ABBVIE Ludwigshafen Germany | Aurobindo Unit III, India | Gilead(Nycomed) Oranienburg DE\n29. First Line Designation | object | Yes | Yes | Yes | Yes | Yes\n30. Weight (Kilograms) | object | 2126 | 941 | 117 | 4228 | 76\n31. Freight Cost (USD) | object | Freight Included in Commodity Cost | 4193.49 | 1767.38 | 12237.61 | 2282.57\n32. Line Item Insurance (USD) | float64 | 224.93 | 3.07 | 65.75 | 158.72 | 27.2\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__divyeshardeshana__supply-chain-shipment-pricing-data/SCMS_Delivery_History_Dataset.csv"]}
{"id": "kaggle__divyeshardeshana__supply-chain-shipment-pricing-data__3", "question": "I have a database of Supply Chain Shipment Pricing Data. As a risk analyst, I want to use the shipment pricing data to assess the financial impact of supply chain disruptions.", "description": "\n\nSupply Chain Shipment Pricing Data\n\nSCMS_Delivery_History_Dataset\n8158 rows x 32 columns\n1. ID | int64 | 108 | 115 | 116 | 161 | 269\n2. Project Code | object | 104-CI-T01 | 108-VN-T01 | 108-VN-T01 | 117-ET-T01 | 108-VN-T01\n3. PQ # | object | Pre-PQ Process | Pre-PQ Process | Pre-PQ Process | Pre-PQ Process | Pre-PQ Process\n4. PO / SO # | object | SCMS-698 | SCMS-753 | SCMS-759 | SCMS-11070 | SCMS-14190\n5. ASN/DN # | object | ASN-727 | ASN-781 | ASN-632 | ASN-916 | ASN-1192\n6. Country | object | C√¥te d'Ivoire | Vietnam | Vietnam | Ethiopia | Vietnam\n7. Managed By | object | PMO - US | PMO - US | PMO - US | PMO - US | PMO - US\n8. Fulfill Via | object | Direct Drop | Direct Drop | Direct Drop | Direct Drop | Direct Drop\n9. Vendor INCO Term | object | CIP | EXW | FCA | EXW | EXW\n10. Shipment Mode | object | Air | Air | Air | Air | Air\n11. PQ First Sent to Client Date | object | Pre-PQ Process | Pre-PQ Process | Pre-PQ Process | Pre-PQ Process | Pre-PQ Process\n12. PO Sent to Vendor Date | object | 7/13/07 | 7/4/07 | 7/4/07 | 10/3/07 | 11/19/07\n13. Scheduled Delivery Date | object | 2-Oct-07 | 15-Oct-07 | 27-Aug-07 | 20-Nov-07 | 21-Jan-08\n14. Delivered to Client Date | object | 2-Oct-07 | 15-Oct-07 | 27-Aug-07 | 20-Nov-07 | 21-Jan-08\n15. Delivery Recorded Date | object | 2-Oct-07 | 15-Oct-07 | 27-Aug-07 | 20-Nov-07 | 21-Jan-08\n16. Product Group | object | ARV | ARV | ARV | ARV | ARV\n17. Sub Classification | object | Pediatric | Pediatric | Adult | Adult | Adult\n18. Vendor | object | BRISTOL-MYERS SQUIBB | Aurobindo Pharma Limited | ABBVIE LOGISTICS (FORMERLY ABBOTT LOGISTICS BV) | Aurobindo Pharma Limited | GILEAD SCIENCES IRELAND, INC.\n19. Molecule/Test Type | object | Didanosine | Nevirapine | Lopinavir/Ritonavir | Stavudine | Tenofovir Disoproxil Fumarate\n20. Brand | object | Videx | Generic | Aluvia | Generic | Viread\n21. Dosage | object | 200mg | 10mg/ml | 200/50mg | 30mg | 300mg\n22. Dosage Form | object | Tablet | Oral suspension | Tablet | Capsule | Tablet\n23. Unit of Measure (Per Pack) | int64 | 60 | 240 | 120 | 60 | 30\n24. Line Item Quantity | int64 | 5513 | 1000 | 500 | 64000 | 1000\n25. Line Item Value | float64 | 140581.5 | 1920.0 | 41095.0 | 99200.0 | 17000.0\n26. Pack Price | float64 | 25.5 | 1.92 | 82.19 | 1.55 | 17.0\n27. Unit Price | float64 | 0.42 | 0.01 | 0.68 | 0.03 | 0.57\n28. Manufacturing Site | object | BMS Meymac, France | Aurobindo Unit III, India | ABBVIE Ludwigshafen Germany | Aurobindo Unit III, India | Gilead(Nycomed) Oranienburg DE\n29. First Line Designation | object | Yes | Yes | Yes | Yes | Yes\n30. Weight (Kilograms) | object | 2126 | 941 | 117 | 4228 | 76\n31. Freight Cost (USD) | object | Freight Included in Commodity Cost | 4193.49 | 1767.38 | 12237.61 | 2282.57\n32. Line Item Insurance (USD) | float64 | 224.93 | 3.07 | 65.75 | 158.72 | 27.2\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__divyeshardeshana__supply-chain-shipment-pricing-data/SCMS_Delivery_History_Dataset.csv"]}
{"id": "kaggle__deepu1109__star-dataset__0", "question": "I have a database of Star dataset to predict star types. As an astrophysicist, I want to classify stars based on their spectral class and understand the relationship between their temperature, luminosity, radius, and absolute magnitude.", "description": "\n\nStar dataset to predict star types\n\n6 class csv\n240 rows x 7 columns\n1. Temperature (K) | int64 | 3068 | 3042 | 2600 | 2800 | 1939\n2. Luminosity(L/Lo) | float64 | 0.0024 | 0.0005 | 0.0003 | 0.0002 | 0.000138\n3. Radius(R/Ro) | float64 | 0.17 | 0.1542 | 0.102 | 0.16 | 0.103\n4. Absolute magnitude(Mv) | float64 | 16.12 | 16.6 | 18.7 | 16.65 | 20.06\n5. Star type | int64 | 0 | 0 | 0 | 0 | 0\n6. Star color | object | Red | Red | Red | Red | Red\n7. Spectral Class | object | M | M | M | M | M\n", "answer_formatter": "Your answer should strictly follow the format:\n## Final report\n### Findings\n1. [finding 1]\n2. [finding 2]\n3. [finding 3]\n......(more findings)\n### Suggestions\n1. [suggestion 1]\n2. [suggestion 2]\n3. [suggestion 3]\n......(more suggestions)\n", "csv_path": ["csv/kaggle__deepu1109__star-dataset/6 class csv.csv"]}
